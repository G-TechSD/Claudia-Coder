# ============================================
# LM Studio Proxy Configuration
# ============================================
# Proxies requests from Docker containers to host LM Studio

upstream lmstudio {
    server host.docker.internal:1234;
    keepalive 32;
}

server {
    listen 80;
    server_name localhost;

    # Health check endpoint
    location /health {
        access_log off;
        return 200 "OK\n";
        add_header Content-Type text/plain;
    }

    # Proxy all other requests to LM Studio
    location / {
        proxy_pass http://lmstudio;
        proxy_http_version 1.1;

        # WebSocket support
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";

        # Headers
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;

        # Timeouts for long-running LLM requests
        proxy_connect_timeout 300s;
        proxy_send_timeout 300s;
        proxy_read_timeout 300s;

        # Buffering settings for streaming responses
        proxy_buffering off;
        proxy_cache off;

        # Large body support for prompts
        client_max_body_size 50M;
    }

    # API v1 endpoint (common LM Studio path)
    location /v1 {
        proxy_pass http://lmstudio/v1;
        proxy_http_version 1.1;

        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;

        proxy_connect_timeout 300s;
        proxy_send_timeout 300s;
        proxy_read_timeout 300s;

        proxy_buffering off;
        client_max_body_size 50M;
    }
}
