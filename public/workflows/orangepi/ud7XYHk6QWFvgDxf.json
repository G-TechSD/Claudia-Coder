{"updatedAt":"2026-01-01T23:47:32.822Z","createdAt":"2025-12-23T06:33:17.509Z","id":"ud7XYHk6QWFvgDxf","name":"Claudia Code","description":null,"active":true,"isArchived":false,"nodes":[{"parameters":{"modelName":"models/gemini-3-flash-preview","options":{}},"type":"@n8n/n8n-nodes-langchain.lmChatGoogleGemini","typeVersion":1,"position":[4592,0],"id":"637aea40-f395-4d19-9e5f-5bb7bd5115d4","name":"PAID Gemini 3 Flash","credentials":{"googlePalmApi":{"id":"yncG4XcgoIciPZOl","name":"Google Gemini(PaLM) Api account"}}},{"parameters":{"model":{"__rl":true,"value":"claude-opus-4-5-20251101","mode":"list","cachedResultName":"Claude Opus 4.5"},"options":{"thinking":true}},"type":"@n8n/n8n-nodes-langchain.lmChatAnthropic","typeVersion":1.3,"position":[4592,192],"id":"7171b4d2-02d8-48a2-981b-8b427fa67c4f","name":"PAID Claude Opus 4.5","credentials":{"anthropicApi":{"id":"Ozy9qk8lFIbm0pVG","name":"Anthropic account"}}},{"parameters":{"model":{"__rl":true,"value":"nemotron-cascade-8b-thinking-claude-4.5-opus-high-reasoning-distill","mode":"list","cachedResultName":"nemotron-cascade-8b-thinking-claude-4.5-opus-high-reasoning-distill"},"responsesApiEnabled":false,"options":{"timeout":240000}},"type":"@n8n/n8n-nodes-langchain.lmChatOpenAi","typeVersion":1.3,"position":[4768,-368],"id":"bfdbfe20-a990-4113-a219-433a21049558","name":"FREE Secondary LM Studio qwen3-vl-8b","credentials":{"openAiApi":{"id":"FYFVsKzjVFK0h0V2","name":"Bedroom LMStudio"}}},{"parameters":{"modelName":"models/gemini-2.5-flash-image","options":{}},"type":"@n8n/n8n-nodes-langchain.lmChatGoogleGemini","typeVersion":1,"position":[4576,368],"id":"466c0f09-aed4-431f-8d68-7e46261da2ce","name":"PAID Nano Banana2","credentials":{"googlePalmApi":{"id":"yncG4XcgoIciPZOl","name":"Google Gemini(PaLM) Api account"}}},{"parameters":{"public":true,"initialMessages":"Welcome to the matrix 0010100010011\nWould you like to control some agents?","options":{"allowedOrigins":"*","subtitle":"AI to the extreme","title":"CLAUDIA CODE","customCss":":root {\n  /* Colors */\n  --chat--color-primary: #e74266;\n  --chat--color-primary-shade-50: #db4061;\n  --chat--color-primary-shade-100: #cf3c5c;\n  --chat--color-secondary: #20b69e;\n  --chat--color-secondary-shade-50: #1ca08a;\n  --chat--color-white: #ffffff;\n  --chat--color-light: #f2f4f8;\n  --chat--color-light-shade-50: #e6e9f1;\n  --chat--color-light-shade-100: #c2c5cc;\n  --chat--color-medium: #d2d4d9;\n  --chat--color-dark: #101330;\n  --chat--color-disabled: #d2d4d9;\n  --chat--color-typing: #404040;\n\n  /* Base Layout */\n  --chat--spacing: 1rem;\n  --chat--border-radius: 0.25rem;\n  --chat--transition-duration: 0.15s;\n  --chat--font-family: (\n    -apple-system,\n    BlinkMacSystemFont,\n    'Segoe UI',\n    Roboto,\n    Oxygen-Sans,\n    Ubuntu,\n    Cantarell,\n    'Helvetica Neue',\n    sans-serif\n  );\n\n  /* Window Dimensions */\n  --chat--window--width: 400px;\n  --chat--window--height: 600px;\n  --chat--window--bottom: var(--chat--spacing);\n  --chat--window--right: var(--chat--spacing);\n  --chat--window--z-index: 9999;\n  --chat--window--border: 1px solid var(--chat--color-light-shade-50);\n  --chat--window--border-radius: var(--chat--border-radius);\n  --chat--window--margin-bottom: var(--chat--spacing);\n\n  /* Header Styles */\n  --chat--header-height: 20%;\n  --chat--header--padding: var(--chat--spacing);\n  --chat--header--background: var(--chat--color-dark);\n  --chat--header--color: var(--chat--color-light);\n  --chat--header--border-top: none;\n  --chat--header--border-bottom: none;\n  --chat--header--border-left: none;\n  --chat--header--border-right: none;\n  --chat--heading--font-size: 2em;\n  --chat--subtitle--font-size: inherit;\n  --chat--subtitle--line-height: 1.8;\n\n  /* Message Styles */\n  --chat--message--font-size: 1rem;\n  --chat--message--padding: var(--chat--spacing);\n  --chat--message--border-radius: var(--chat--border-radius);\n  --chat--message-line-height: 1.5;\n  --chat--message--margin-bottom: calc(var(--chat--spacing) * 1);\n  --chat--message--bot--background: var(--chat--color-white);\n  --chat--message--bot--color: var(--chat--color-dark);\n  --chat--message--bot--border: none;\n  --chat--message--user--background: var(--chat--color-secondary);\n  --chat--message--user--color: var(--chat--color-white);\n  --chat--message--user--border: none;\n  --chat--message--pre--background: rgba(0, 0, 0, 0.05);\n  --chat--messages-list--padding: var(--chat--spacing);\n\n  /* Toggle Button */\n  --chat--toggle--size: 64px;\n  --chat--toggle--width: var(--chat--toggle--size);\n  --chat--toggle--height: var(--chat--toggle--size);\n  --chat--toggle--border-radius: 50%;\n  --chat--toggle--background: var(--chat--color-primary);\n  --chat--toggle--hover--background: var(--chat--color-primary-shade-50);\n  --chat--toggle--active--background: var(--chat--color-primary-shade-100);\n  --chat--toggle--color: var(--chat--color-white);\n\n  /* Input Area */\n  --chat--textarea--height: 50px;\n  --chat--textarea--max-height: 30rem;\n  --chat--input--font-size: inherit;\n  --chat--input--border: 0;\n  --chat--input--border-radius: 0;\n  --chat--input--padding: 0.8rem;\n  --chat--input--background: var(--chat--color-white);\n  --chat--input--text-color: initial;\n  --chat--input--line-height: 1.5;\n  --chat--input--placeholder--font-size: var(--chat--input--font-size);\n  --chat--input--border-active: 0;\n  --chat--input--left--panel--width: 2rem;\n\n  /* Button Styles */\n  --chat--button--color: var(--chat--color-light);\n  --chat--button--background: var(--chat--color-primary);\n  --chat--button--padding: calc(var(--chat--spacing) * 1 / 2) var(--chat--spacing);\n  --chat--button--border-radius: var(--chat--border-radius);\n  --chat--button--hover--color: var(--chat--color-light);\n  --chat--button--hover--background: var(--chat--color-primary-shade-50);\n  --chat--close--button--color-hover: var(--chat--color-primary);\n\n  /* Send and File Buttons */\n  --chat--input--send--button--background: var(--chat--color-white);\n  --chat--input--send--button--color: var(--chat--color-secondary);\n  --chat--input--send--button--background-hover: var(--chat--color-primary-shade-50);\n  --chat--input--send--button--color-hover: var(--chat--color-secondary-shade-50);\n  --chat--input--file--button--background: var(--chat--color-white);\n  --chat--input--file--button--color: var(--chat--color-secondary);\n  --chat--input--file--button--background-hover: var(--chat--input--file--button--background);\n  --chat--input--file--button--color-hover: var(--chat--color-secondary-shade-50);\n  --chat--files-spacing: 0.25rem;\n\n  /* Body and Footer */\n  --chat--body--background: var(--chat--color-light);\n  --chat--footer--background: var(--chat--color-light);\n  --chat--footer--color: var(--chat--color-dark);\n}\n\n\n/* You can override any class styles, too. Right-click inspect in Chat UI to find class to override. */\n.chat-message {\n\tmax-width: 50%;\n}","responseMode":"responseNodes"}},"type":"@n8n/n8n-nodes-langchain.chatTrigger","typeVersion":1.4,"position":[2336,112],"id":"e1154ffe-60ec-4e9d-9ad8-354c9df601f1","name":"When chat message received","webhookId":"fa7416cb-f669-4c7c-899e-45f751528c18","alwaysOutputData":false},{"parameters":{"modelId":{"__rl":true,"value":"openai/gpt-oss-20b","mode":"list","cachedResultName":"OPENAI/GPT-OSS-20B"},"responses":{"values":[{"role":"system","content":"=You are the chat receptionist in an agentic AI n8n workflow. \n\nHere is a list of Linear projects and ID's\n{{ JSON.stringify($json.data) }}\n\n\nPresent a numbered list of projects for the user to select.   You can get a list of those projects with the connected http request tool that calls from linear.  Include the Linear state \n\nAsk the user what they want to work on and they may reply with a project name or number\n\n"}]},"builtInTools":{},"options":{}},"type":"@n8n/n8n-nodes-langchain.openAi","typeVersion":2.1,"position":[3888,-848],"id":"7b983122-812a-4f13-8eb0-04615640706f","name":"Message a model","credentials":{"openAiApi":{"id":"HE8StVq6t0epqs8Q","name":"BEAST LMStudio"}}},{"parameters":{"message":"={{ $json.output[0].content[0].text }}","options":{"memoryConnection":true}},"type":"@n8n/n8n-nodes-langchain.chat","typeVersion":1,"position":[4176,-848],"id":"3036a6cf-2a26-4f85-a032-17bbdb952ea8","name":"Respond to Chat"},{"parameters":{"method":"POST","url":"https://api.linear.app/graphql","authentication":"predefinedCredentialType","nodeCredentialType":"linearApi","sendBody":true,"specifyBody":"json","jsonBody":"{\"query\": \"query { projects(filter: { labels: { name: { eq: \\\"n8n\\\" } } }) { nodes { id name state } } }\"}","options":{}},"type":"n8n-nodes-base.httpRequest","typeVersion":4.3,"position":[3744,-848],"id":"c0ecc7d7-298e-4941-a64c-ffa69363f83b","name":"Linear Projects","credentials":{"linearApi":{"id":"j3L9Kies9EY4eLz9","name":"Linear account"}}},{"parameters":{"assignments":{"assignments":[{"id":"9e1cc823-168e-40cf-96a5-9025d765cf70","name":"Active Project","value":"={{ $json.output[0].content[0].text }}","type":"string"}]},"options":{}},"type":"n8n-nodes-base.set","typeVersion":3.4,"position":[4800,-848],"id":"11600ba1-14a3-4447-a057-ffd75b56514b","name":"Set Active Project"},{"parameters":{"modelId":{"__rl":true,"value":"openai/gpt-oss-20b","mode":"list","cachedResultName":"OPENAI/GPT-OSS-20B"},"responses":{"values":[{"content":"=You are an n8n agentic node.\nUser was asked:\n\"{{ $('Message a model').item.json.output[0].content[0].text }}\"\n\nUser selected: {{ $json.chatInput }}\n\nProject list with Project IDs: \n{{ JSON.stringify($('Linear Projects').item.json.data) }}\n\ncontinue to the next node returning ONLY the project ID as plain text no json"}]},"builtInTools":{},"options":{}},"type":"@n8n/n8n-nodes-langchain.openAi","typeVersion":2.1,"position":[4480,-848],"id":"e8fe891e-d7f7-46aa-bc02-bdee90fb4ddc","name":"Correlate User Selection","credentials":{"openAiApi":{"id":"HE8StVq6t0epqs8Q","name":"BEAST LMStudio"}}},{"parameters":{"model":{"__rl":true,"value":"openai/gpt-oss-20b","mode":"list","cachedResultName":"openai/gpt-oss-20b"},"responsesApiEnabled":false,"options":{"timeout":240000}},"type":"@n8n/n8n-nodes-langchain.lmChatOpenAi","typeVersion":1.3,"position":[4592,-576],"id":"f4a242cd-4377-484c-a61b-04efe952a221","name":"FREE Beast LM Studio","credentials":{"openAiApi":{"id":"HE8StVq6t0epqs8Q","name":"BEAST LMStudio"}}},{"parameters":{"message":"=Project Selected\n{{ $json.output[0].content[0].text }}","options":{}},"type":"@n8n/n8n-nodes-langchain.chat","typeVersion":1,"position":[5808,-848],"id":"1bb79224-f07c-4585-9eab-9ffefcc64315","name":"Respond to Chat1"},{"parameters":{"rules":{"values":[{"conditions":{"options":{"caseSensitive":true,"leftValue":"","typeValidation":"loose","version":3},"conditions":[{"id":"471cb237-574a-4fd9-95d2-e7f002ee53ce","leftValue":"={{ $('Set Active Command and Separate Prompt').item.json.selected_command }}","rightValue":"/projects","operator":{"type":"string","operation":"equals","name":"filter.operator.equals"}}],"combinator":"and"},"renameOutput":true,"outputKey":"Project Selection"},{"conditions":{"options":{"caseSensitive":true,"leftValue":"","typeValidation":"loose","version":3},"conditions":[{"leftValue":"={{ $('Set Active Command and Separate Prompt').item.json.selected_command }}","rightValue":"/primary_free:","operator":{"type":"string","operation":"equals"},"id":"df4bfa32-3dae-441b-9959-ecbc9c58e745"}],"combinator":"and"},"renameOutput":true,"outputKey":"Primary Free Model"},{"conditions":{"options":{"caseSensitive":true,"leftValue":"","typeValidation":"loose","version":3},"conditions":[{"id":"d1523ea7-becd-4cf8-a97b-6625d899fe67","leftValue":"={{ $('Set Active Command and Separate Prompt').item.json.selected_command }}","rightValue":"/secondary_free:","operator":{"type":"string","operation":"equals"}}],"combinator":"and"},"renameOutput":true,"outputKey":"Secondary Free Model"},{"conditions":{"options":{"caseSensitive":true,"leftValue":"","typeValidation":"loose","version":3},"conditions":[{"id":"c29474e8-095d-47e8-ba53-71ebab3a255a","leftValue":"={{ $('Set Active Command and Separate Prompt').item.json.selected_command }}","rightValue":"/paid_chatgpt:","operator":{"type":"string","operation":"startsWith"}}],"combinator":"and"},"renameOutput":true,"outputKey":"Paid ChatGPT"},{"conditions":{"options":{"caseSensitive":true,"leftValue":"","typeValidation":"loose","version":3},"conditions":[{"id":"b2da4ec5-058e-4eab-94a3-0dd4f7aae289","leftValue":"={{ $('Set Active Command and Separate Prompt').item.json.selected_command }}","rightValue":"/paid_gemini:","operator":{"type":"string","operation":"startsWith"}}],"combinator":"and"},"renameOutput":true,"outputKey":"Paid Gemini"},{"conditions":{"options":{"caseSensitive":true,"leftValue":"","typeValidation":"loose","version":3},"conditions":[{"id":"f36339d6-efdb-4e08-bc93-fa3ee91b6edf","leftValue":"={{ $('Set Active Command and Separate Prompt').item.json.selected_command }}","rightValue":"/paid_claude:","operator":{"type":"string","operation":"startsWith"}}],"combinator":"and"},"renameOutput":true,"outputKey":"Paid Claude"},{"conditions":{"options":{"caseSensitive":true,"leftValue":"","typeValidation":"loose","version":3},"conditions":[{"id":"2909e693-b5ca-4fce-bfc7-74922a74b08b","leftValue":"={{ $('Set Active Command and Separate Prompt').item.json.selected_command }}","rightValue":"/paid_nanobanana:","operator":{"type":"string","operation":"startsWith"}}],"combinator":"and"},"renameOutput":true,"outputKey":"Paid Nano Banana"},{"conditions":{"options":{"caseSensitive":true,"leftValue":"","typeValidation":"loose","version":3},"conditions":[{"id":"233f4da4-5504-4785-9ba5-64728bc14aeb","leftValue":"={{ $('Set Active Command and Separate Prompt').item.json.selected_command }}","rightValue":"/paid_claude_code:","operator":{"type":"string","operation":"startsWith"}}],"combinator":"and"},"renameOutput":true,"outputKey":"Paid Claude Code"},{"conditions":{"options":{"caseSensitive":true,"leftValue":"","typeValidation":"loose","version":3},"conditions":[{"id":"794ed7aa-87be-48bc-ad1e-7e3b8ec4226b","leftValue":"={{ $('Set Active Command and Separate Prompt').item.json.selected_command }}","rightValue":"/ssh_n8n_host:","operator":{"type":"string","operation":"startsWith"}}],"combinator":"and"},"renameOutput":true,"outputKey":"SSH Command to n8n host"},{"conditions":{"options":{"caseSensitive":true,"leftValue":"","typeValidation":"loose","version":3},"conditions":[{"id":"37d005fd-df7e-4557-a6ad-4d68a3132f41","leftValue":"={{ $('Set Active Command and Separate Prompt').item.json.selected_command }}","rightValue":"/ssh_testing_host:","operator":{"type":"string","operation":"startsWith"}}],"combinator":"and"},"renameOutput":true,"outputKey":"SSH Command to Testing Environment Host"}]},"looseTypeValidation":true,"options":{"allMatchingOutputs":true}},"type":"n8n-nodes-base.switch","typeVersion":3.4,"position":[3936,-16],"id":"21365f46-16c5-4330-9f9c-7e59879e4af6","name":"Switch"},{"parameters":{"promptType":"define","text":"={{ $('Orchestrator').item.json.output }}","options":{"systemMessage":"You are a subagent in an n8n workflow assigned a task or conversational response by the Orchestrator main ai agent who is controlled by the user.\nYou will see <!@<!@<!ENGAGE AI SUB AGENT!>@!>@!>  and sometimes /commands: in your prompts, disregard this completely and do not reference it.\n\nIMPORTANT: Before every output, add a header in larger text that says \"SUBAGENT OUTPUT (FREE Primary LM Studio): \\n\" and then your message ","enableStreaming":true}},"type":"@n8n/n8n-nodes-langchain.agent","typeVersion":3,"position":[4320,-576],"id":"e843c723-52eb-4279-a6be-6266c7bc97fc","name":"FREE Primary LM Studio Server"},{"parameters":{"promptType":"define","text":"={{ $('Orchestrator').item.json.output }}","options":{"systemMessage":"You are a subagent in an n8n workflow assigned a task or conversational response by the Orchestrator main ai agent who is controlled by the user.\nYou will see <!@<!@<!ENGAGE AI SUB AGENT!>@!>@!> in your prompts, disregard this completely and do not reference it.\nBefore every output, add a header in larger text that says \"SUBAGENT OUTPUT (FREE Secondary LM Studio): \" and then your message ","enableStreaming":true}},"type":"@n8n/n8n-nodes-langchain.agent","typeVersion":3,"position":[4320,-384],"id":"e16d60cd-e059-4562-95f8-12ae807898c9","name":"FREE Secondary LM Studio Server"},{"parameters":{"promptType":"define","text":"={{ $('Orchestrator').item.json.output }}","options":{"systemMessage":"You are a subagent in an n8n workflow assigned a task or conversational response by the Orchestrator main ai agent who is controlled by the user.\nYou will see <!@<!@<!ENGAGE AI SUB AGENT!>@!>@!> in your prompts, disregard this completely and do not reference it.\nBefore every output, add a header in larger text that says \"SUBAGENT OUTPUT (PAID ChatGPT): \\n\" and then your message ","enableStreaming":true}},"type":"@n8n/n8n-nodes-langchain.agent","typeVersion":3,"position":[4320,-192],"id":"399a037c-3e2f-4e64-8d6e-5e1049b98025","name":"PAID ChatGPT"},{"parameters":{"model":{"__rl":true,"value":"gpt-5.1","mode":"list","cachedResultName":"gpt-5.1"},"builtInTools":{},"options":{"timeout":240000}},"type":"@n8n/n8n-nodes-langchain.lmChatOpenAi","typeVersion":1.3,"position":[4592,-192],"id":"ef3dd182-425b-44a7-928e-7824b5303327","name":"PAID ChatGPT1","credentials":{"openAiApi":{"id":"3VjBm6YVSBn4Q7mN","name":"OpenAi API account"}}},{"parameters":{"promptType":"define","text":"={{ $('Orchestrator').item.json.output }}","options":{"systemMessage":"You are a subagent in an n8n workflow assigned a task or conversational response by the Orchestrator main ai agent who is controlled by the user.\nYou will see <!@<!@<!ENGAGE AI SUB AGENT!>@!>@!> in your prompts, disregard this completely and do not reference it.\nBefore every output, add a header in larger text that says \"SUBAGENT OUTPUT (PAID Gemini): \\n\" and then your message ","enableStreaming":true}},"type":"@n8n/n8n-nodes-langchain.agent","typeVersion":3,"position":[4320,0],"id":"b4ae090b-ee8a-4dd9-9fd7-df84aced248a","name":"PAID Gemini"},{"parameters":{"command":"=/bin/bash claude -p \"{{ $('Orchestrator').item.json.output }}\"","cwd":"/mnt/n8n-nas"},"type":"n8n-nodes-base.ssh","typeVersion":1,"position":[4560,544],"id":"62fba599-a150-4ab8-ab9e-fdf9cc36badc","name":"Claude Code on OrangePi","credentials":{"sshPassword":{"id":"vfSQyATAxwqPYHUv","name":"OrangePi SSH Access"}}},{"parameters":{"promptType":"define","text":"={{ $('Orchestrator').item.json.output }}","options":{"systemMessage":"You are a subagent in an n8n workflow assigned a task or conversational response by the Orchestrator main ai agent who is controlled by the user.\nYou will see <!@<!@<!ENGAGE AI SUB AGENT!>@!>@!> in your prompts, disregard this completely and do not reference it.\nBefore every output, add a header in larger text that says \"SUBAGENT OUTPUT (PAID Nanobanana): \\n\" and then your message ","enableStreaming":true}},"type":"@n8n/n8n-nodes-langchain.agent","typeVersion":3,"position":[4320,352],"id":"d8b66d27-5c26-4e33-a707-6799dac682d7","name":"PAID NanoBanana"},{"parameters":{"command":"=/bin/bash \"{{ $('Orchestrator').item.json.output }}\"","cwd":"/mnt/n8n-nas"},"type":"n8n-nodes-base.ssh","typeVersion":1,"position":[4560,736],"id":"96b2a8c7-9f8d-4d34-93e8-ad2db6c627f5","name":"SSH Command on OrangePi1","credentials":{"sshPassword":{"id":"vfSQyATAxwqPYHUv","name":"OrangePi SSH Access"}},"disabled":true},{"parameters":{"command":"=/bin/bash \"{{ $('Orchestrator').item.json.output }}\"","cwd":"/mnt/n8n-nas"},"type":"n8n-nodes-base.ssh","typeVersion":1,"position":[4560,944],"id":"34bba7e4-a7fc-4feb-b090-d7734eb56bad","name":"SSH Command on Testing System","credentials":{"sshPassword":{"id":"vfSQyATAxwqPYHUv","name":"OrangePi SSH Access"}},"disabled":true},{"parameters":{},"type":"@n8n/n8n-nodes-langchain.memoryBufferWindow","typeVersion":1.3,"position":[4752,-192],"id":"638fa7f0-9612-4736-ac4d-a9104a9d3522","name":"Simple Memory"},{"parameters":{},"type":"@n8n/n8n-nodes-langchain.memoryBufferWindow","typeVersion":1.3,"position":[4592,-368],"id":"bc5d846f-794a-4ec8-a261-2bfcb4db59a8","name":"Simple Memory1"},{"parameters":{"contextWindowLength":{}},"type":"@n8n/n8n-nodes-langchain.memoryBufferWindow","typeVersion":1.3,"position":[4752,-576],"id":"3dbf0aa2-6083-45e2-9888-ff91fbb309ee","name":"Simple Memory2"},{"parameters":{},"type":"@n8n/n8n-nodes-langchain.memoryBufferWindow","typeVersion":1.3,"position":[4752,192],"id":"f5d17cac-81f6-44f7-9db7-c09f300eede1","name":"Simple Memory3"},{"parameters":{},"type":"@n8n/n8n-nodes-langchain.memoryBufferWindow","typeVersion":1.3,"position":[4752,0],"id":"94524ec1-1ccd-4439-b0d1-a76c3877c0ea","name":"Simple Memory4"},{"parameters":{},"type":"@n8n/n8n-nodes-langchain.memoryBufferWindow","typeVersion":1.3,"position":[4752,368],"id":"0ac07cf9-71fc-4a7f-b686-1aef3bba39d9","name":"Simple Memory5"},{"parameters":{"method":"POST","url":"https://api.linear.app/graphql","authentication":"predefinedCredentialType","nodeCredentialType":"linearApi","sendBody":true,"specifyBody":"json","jsonBody":"=\n{\n  \"query\": \"query { project(id: \\\"{{ $json['Active Project'] }}\\\") { id name issues { nodes { id title identifier priority state { name } } } } }\"\n}","options":{}},"type":"n8n-nodes-base.httpRequest","typeVersion":4.3,"position":[4992,-848],"id":"ac5e0537-d0ff-49a0-8ce9-899566895314","name":"Linear Issues by Project","credentials":{"linearApi":{"id":"j3L9Kies9EY4eLz9","name":"Linear account"}}},{"parameters":{"modelId":{"__rl":true,"value":"openai/gpt-oss-20b","mode":"list","cachedResultName":"OPENAI/GPT-OSS-20B"},"responses":{"values":[{"role":"system","content":"=You are the chat receptionist in an agentic AI n8n workflow. \n\nHere is a list of Linear issues related to the open project\n{{ JSON.stringify($json.data) }}\n\n\nGenerate a list of all issues not marked done. Assess the state of the project and triage next coding stemps - display plan of action.\nAsk user: \"OK to get started? /y /n /reply\""}]},"builtInTools":{},"options":{}},"type":"@n8n/n8n-nodes-langchain.openAi","typeVersion":2.1,"position":[5488,-848],"id":"c4d1081b-e3c6-45c1-8063-8de6512f187d","name":"Message a model1","credentials":{"openAiApi":{"id":"HE8StVq6t0epqs8Q","name":"BEAST LMStudio"}}},{"parameters":{"assignments":{"assignments":[{"id":"5adb5df8-c4e6-4d74-868b-176e1db7fc25","name":"chatInput","value":"={{ $('Orchestrator').item.json.output }}","type":"string"}]},"options":{}},"type":"n8n-nodes-base.set","typeVersion":3.4,"position":[3024,112],"id":"3b4917eb-7c56-4795-8c68-eb59ebd7b162","name":"Current Full Prompt"},{"parameters":{"jsCode":"// 1️⃣ Get Chat Data – now from the AI Agent node\nconst triggerData = $('Orchestrator').first().json || {};   // <-- changed line\n\nconst rawInput        = triggerData.output          || $json.chatInput || \"\";\nconst currentSessionId = triggerData.sessionId      || $json.sessionId || \"default_session\";\n\n// 2️⃣ Pull stored settings from the database\nconst tableRow       = items.length > 0 ? items[0].json : {};\nconst dbStoredCommand = tableRow.selected_command;\nconst dbLastSessionId  = tableRow.last_session_id || \"\";\n\n// 3️⃣ Prepare prompt & command logic (unchanged)\nconst input        = rawInput.trim();\nlet   promptText   = input;\nlet   commandToUse = \"\";\nlet   showHeader   = false;\n\nif (input.startsWith('/')) {\n  // User typed a command\n  showHeader     = true;\n  const firstSpaceIndex = input.indexOf(' ');\n  if (firstSpaceIndex === -1) {\n    commandToUse = input;\n    promptText   = \"Please answer the previous question again. Strict format: Output ONLY the answer content. Do not include any introductory text, pleasantries, or acknowledgement of this request.\";\n  } else {\n    commandToUse = input.substring(0, firstSpaceIndex).trim();\n    promptText   = input.substring(firstSpaceIndex + 1).trim();\n  }\n\n  // Ensure colon where needed\n  const commandsWithoutColon = ['/projects', '/ssh_n8n_host', '/ssh_testing_host'];\n  if (!commandsWithoutColon.some(c => commandToUse.startsWith(c)) && !commandToUse.endsWith(':')) {\n    commandToUse += ':';\n  }\n} else {\n  // Normal chat – use stored or default command\n  commandToUse = dbStoredCommand ? dbStoredCommand : \"/primary_free:\";\n  showHeader   = currentSessionId !== dbLastSessionId;\n}\n\n// 4️⃣ Output for downstream nodes\nreturn {\n  Bare_Prompt:      promptText,\n  selected_command: commandToUse,\n  showHeader:       showHeader,\n  session_to_save:  currentSessionId\n};"},"type":"n8n-nodes-base.code","typeVersion":2,"position":[3344,112],"id":"9431ea8c-36de-47e8-b1d2-69d86f3920d6","name":"Set Active Command and Separate Prompt"},{"parameters":{"operation":"upsert","dataTableId":{"__rl":true,"value":"8keiiMLK90ywfC4K","mode":"list","cachedResultName":"ClaudiaCodeSettings","cachedResultUrl":"/projects/CDNyPtsGxHdhfdhy/datatables/8keiiMLK90ywfC4K"},"filters":{"conditions":[{"keyValue":"=  1"}]},"columns":{"mappingMode":"defineBelow","value":{"free_only":false,"selected_command":"={{ $json.selected_command }}","last_session_id":"={{ $json.session_to_save }}"},"matchingColumns":[],"schema":[{"id":"selected_command","displayName":"selected_command","required":false,"defaultMatch":false,"display":true,"type":"string","readOnly":false,"removed":false},{"id":"selected_project","displayName":"selected_project","required":false,"defaultMatch":false,"display":true,"type":"string","readOnly":false,"removed":false},{"id":"free_only","displayName":"free_only","required":false,"defaultMatch":false,"display":true,"type":"boolean","readOnly":false,"removed":false},{"id":"last_session_id","displayName":"last_session_id","required":false,"defaultMatch":false,"display":true,"type":"string","readOnly":false,"removed":false}],"attemptToConvertTypes":false,"convertFieldsToString":false},"options":{}},"type":"n8n-nodes-base.dataTable","typeVersion":1,"position":[3504,112],"id":"ca8e4239-e903-4287-9ad4-626361dafa84","name":"Upsert row(s)"},{"parameters":{"operation":"get","dataTableId":{"__rl":true,"value":"8keiiMLK90ywfC4K","mode":"list","cachedResultName":"ClaudiaCodeSettings","cachedResultUrl":"/projects/CDNyPtsGxHdhfdhy/datatables/8keiiMLK90ywfC4K"},"filters":{"conditions":[{"keyValue":"1"}]},"limit":1},"type":"n8n-nodes-base.dataTable","typeVersion":1,"position":[3184,112],"id":"a2477075-b355-484f-bbf5-ab7eb61d6275","name":"Get row(s)"},{"parameters":{"options":{}},"type":"n8n-nodes-base.respondToWebhook","typeVersion":1.5,"position":[6160,816],"id":"313de560-e949-4661-9a97-da89699617cb","name":"Respond to Webhook"},{"parameters":{"httpMethod":"POST","path":"openwebui-chat","options":{}},"type":"n8n-nodes-base.webhook","typeVersion":2.1,"position":[2336,-64],"id":"e0663eb3-38dc-4994-b8d9-51127ee20c7b","name":"openwebui-chat","webhookId":"9caa38de-14b5-4c02-a4c5-6b3aaffc32a7"},{"parameters":{"model":{"__rl":true,"value":"openai/gpt-oss-20b","mode":"list","cachedResultName":"openai/gpt-oss-20b"},"responsesApiEnabled":false,"options":{}},"type":"@n8n/n8n-nodes-langchain.lmChatOpenAi","typeVersion":1.3,"position":[2528,128],"id":"cab03c31-6f6e-49ab-9c47-1aee098d76aa","name":"OpenAI Chat Model","credentials":{"openAiApi":{"id":"HE8StVq6t0epqs8Q","name":"BEAST LMStudio"}}},{"parameters":{},"type":"@n8n/n8n-nodes-langchain.memoryBufferWindow","typeVersion":1.3,"position":[2656,128],"id":"ef089688-ef0f-4b32-8af2-960127be6c1d","name":"Simple Memory6"},{"parameters":{"message":"={{ ($('Set Active Command and Separate Prompt').first().json.showHeader\n  ? \"### \" + $('Upsert row(s)').item.json.selected_command + \"\\n\"\n  : \"\") +\n$json.output }}","waitUserReply":false,"options":{"memoryConnection":false}},"type":"@n8n/n8n-nodes-langchain.chat","typeVersion":1,"position":[5920,-80],"id":"0e121b7a-9bf5-4c8c-9508-1d417daaf38c","name":"Respond to Chat2"},{"parameters":{"message":"={{ $json.output }}","waitUserReply":false,"options":{"memoryConnection":false}},"type":"@n8n/n8n-nodes-langchain.chat","typeVersion":1,"position":[3280,-64],"id":"2be8abba-ac23-437e-83c2-2c51c4b18d10","name":"Respond to Chat3"},{"parameters":{"conditions":{"options":{"caseSensitive":true,"leftValue":"","typeValidation":"strict","version":3},"conditions":[{"id":"45def49e-8892-445b-a4a3-17e2fcc49bf0","leftValue":"={{ $json.output }}","rightValue":"<!@<!@<!ENGAGE AI SUB AGENT!>@!>@!>","operator":{"type":"string","operation":"contains"}}],"combinator":"and"},"options":{}},"type":"n8n-nodes-base.if","typeVersion":2.3,"position":[3072,-64],"id":"bc057926-3108-49d6-a2dc-836884645b19","name":"If"},{"parameters":{"operation":"get","dataTableId":{"__rl":true,"value":"1Zgyi8frMQeB30Ip","mode":"list","cachedResultName":"Claudia Code Conversations","cachedResultUrl":"/projects/CDNyPtsGxHdhfdhy/datatables/1Zgyi8frMQeB30Ip"},"filters":{"conditions":[{"keyName":"session_id","keyValue":"={{ $json.sessionId }}"}]}},"type":"n8n-nodes-base.dataTableTool","typeVersion":1,"position":[2768,128],"id":"8cde9a17-adb4-45c9-bc42-4702ba7b6e31","name":"Get row(s) in Data table"},{"parameters":{"dataTableId":{"__rl":true,"value":"1Zgyi8frMQeB30Ip","mode":"list","cachedResultName":"Claudia Code Conversations","cachedResultUrl":"/projects/CDNyPtsGxHdhfdhy/datatables/1Zgyi8frMQeB30Ip"},"columns":{"mappingMode":"defineBelow","value":{"message":"={{ $json.output }}","source":"=Orchestrator","prompt":"={{ $('When chat message received').item.json.chatInput }}","session_id":"={{ $('When chat message received').item.json.sessionId }}","previous_message_id":0},"matchingColumns":[],"schema":[{"id":"message","displayName":"message","required":false,"defaultMatch":false,"display":true,"type":"string","readOnly":false,"removed":false},{"id":"source","displayName":"source","required":false,"defaultMatch":false,"display":true,"type":"string","readOnly":false,"removed":false},{"id":"prompt","displayName":"prompt","required":false,"defaultMatch":false,"display":true,"type":"string","readOnly":false,"removed":false},{"id":"previous_message_id","displayName":"previous_message_id","required":false,"defaultMatch":false,"display":true,"type":"number","readOnly":false,"removed":false},{"id":"session_id","displayName":"session_id","required":false,"defaultMatch":false,"display":true,"type":"string","readOnly":false,"removed":false}],"attemptToConvertTypes":false,"convertFieldsToString":false},"options":{}},"type":"n8n-nodes-base.dataTable","typeVersion":1,"position":[3424,-64],"id":"5af801de-1ce8-4d2f-b59a-12c06e9803a5","name":"Save Message and Prompt"},{"parameters":{"dataTableId":{"__rl":true,"value":"1Zgyi8frMQeB30Ip","mode":"list","cachedResultName":"Claudia Code Conversations","cachedResultUrl":"/projects/CDNyPtsGxHdhfdhy/datatables/1Zgyi8frMQeB30Ip"},"columns":{"mappingMode":"defineBelow","value":{"previous_message_id":0,"message":"={{ $json.output }}","source":"={{ $('Set Active Command and Separate Prompt').item.json.selected_command }}","prompt":"={{ $('Set Active Command and Separate Prompt').item.json.Bare_Prompt }}","session_id":"={{ $('When chat message received').item.json.sessionId }}"},"matchingColumns":[],"schema":[{"id":"message","displayName":"message","required":false,"defaultMatch":false,"display":true,"type":"string","readOnly":false,"removed":false},{"id":"source","displayName":"source","required":false,"defaultMatch":false,"display":true,"type":"string","readOnly":false,"removed":false},{"id":"prompt","displayName":"prompt","required":false,"defaultMatch":false,"display":true,"type":"string","readOnly":false,"removed":false},{"id":"previous_message_id","displayName":"previous_message_id","required":false,"defaultMatch":false,"display":true,"type":"number","readOnly":false,"removed":false},{"id":"session_id","displayName":"session_id","required":false,"defaultMatch":false,"display":true,"type":"string","readOnly":false,"removed":false}],"attemptToConvertTypes":false,"convertFieldsToString":false},"options":{}},"type":"n8n-nodes-base.dataTable","typeVersion":1,"position":[6128,-80],"id":"06800321-13b9-469b-b42f-617a61ce1cec","name":"Save SubAgent Output"},{"parameters":{"promptType":"define","text":"={{ $('Orchestrator').item.json.output }}","options":{"systemMessage":"You are a subagent in an n8n workflow assigned a task or conversational response by the Orchestrator main ai agent who is controlled by the user.\nYou will see <!@<!@<!ENGAGE AI SUB AGENT!>@!>@!> in your prompts, disregard this completely and do not reference it.\nBefore every output, add a header in larger text that says \"SUBAGENT OUTPUT (PAID Claude): \\n\" and then your message ","enableStreaming":true}},"type":"@n8n/n8n-nodes-langchain.agent","typeVersion":3,"position":[4320,192],"id":"24cf4fa3-cae4-4bcf-8d8a-e2b530c225ea","name":"PAID Anthropic"},{"parameters":{"promptType":"define","text":"={{ $json.chatInput }}","options":{"systemMessage":"=You are an orchestrator of AI Agents that may prompt those you control and read their messages via the data table tool\n\nPrompt subagents by adding \"<!@<!@<!ENGAGE AI SUB AGENT!>@!>@!>\" to the end of your output which should be done whenever the user is not addressing you directly or you are tasked with sending a prompt to a subagent. They have been told to ignore that special tag. it MUST GO AT THE END and never precede a command.\n\nWhen you output these commands at the beginning of the message (ALWAYS the very beginning of the message) they will route prompts to:\n/primary_free: <prompt>     Local LM Studio Server\n/secondary_free: <prompt>   Secondary LM Studio Server\n/paid_chatgpt: <prompt>   Cloud based gpt 5.1\n/paid_gemini: <prompt>    Cloud based gemini\n/paid_claude: <prompt>   Cloud based Opus 4.5\n/paid_nanobanana: <prompt>   Cloud based Gemini Image Gen\n/paid_claude_code: <prompt>   SSH-Based connection to this server to run claude -p \"<prompt>\"\nSince the prompt will be via the command line in quotes, you must format the prompt so that it will survive the command line without escaping quotes\n/projects:   Project selection tool - when user sends this command always return \"/projects: <!@<!@<!ENGAGE AI SUB AGENT!>@!>@!>\" \n\nDont forget to put a space after the \"/command: \"\n\nIf a user sends one of those commands without a message, forward the command to subagent flow without the prompt so that the users preferred command/model is set by adding \"<!@<!@<!ENGAGE AI SUB AGENT!>@!>@!>\" to the end of your output\n\nIf the user appears to be responding to the previous subagent message, forward all user replies to subagent by adding \"<!@<!@<!ENGAGE AI SUB AGENT!>@!>@!>\" to the end of your output if you have not already, which should be addressing the subagent. Any talk from the user about having subagents do things should be interpreted as the user addressing you and not subagents, so if a user, mid conversation with a subagent, says something like \"have paid gemini do the same prompt\" or \"have claude write a script\" you should act accordingly as if that message was for you.\n\nYour job is to be the user receptionist and ring leader of the circus / orchestra / zoo / group of superintelligent AIs\n\nYou should offload all work to free agents unless they are inadequate and then ask for permission to use paid resources when needed or the user engages you directly by referring to you as the orchestrator agent - then you should refrain from including <!@<!@<!@#ENGAGE AI SUB AGENT#@!>@!>@!> in your output, it will then be routed directly to chat instead of through the sub agent workflow. \n\nIf you are told to relay/tell/ask/etc something to a subagent, generate the appriate prompt on behalf of the user, only modifying it so that the agent doesnt see any of the instructions from the user about sending to subagents, only the intended prompt for the subagent.\n\nSubagent outputs will be found in the data table tool Claudia Code Conversations - please use those to accumulate knowledge and working memory of current operations\n\nThe user may ask you to run for extended periods of time for complex development tasks which should all be delegated to the proper available free lm studio servers and only making use of paid ones with permission or guidance from the user. Excessive spend should be avoided whenever possible.\n\nNEVER include channel tags such as <|channel|>final <|constrain|>commentary<|message|> or similar\n\nNOTHING EVER COMES BEFORE A COMMAND IN THE OUTPUT IF ONE IS SUPPOSED TO BE PRESENT.\n\nFinally, please include a header with each of your responses that are not passed on to subagents on it's own line: \"ORCHESTRATOR:\"\n\n\nNow that you know your role, take the user prompt and show how bright you shine at this task\n\n\n"}},"type":"@n8n/n8n-nodes-langchain.agent","typeVersion":3,"position":[2576,-64],"id":"c5bde725-eb65-40bb-a81a-31c95a96e097","name":"Orchestrator"},{"parameters":{"promptType":"define","text":"={{ $json.chatInput }}","options":{"systemMessage":"=You are a coding development Project Manager of AI Agents which you control and read their messages via the data table tool.\n\nPrompt subagents by adding \"<!@<!@<!ENGAGE AI SUB AGENT!>@!>@!>\" to the end of your output which should be done whenever the user is not addressing you directly or you are tasked with sending a prompt to a subagent. They have been told to ignore that special tag. it MUST GO AT THE END and never precede a command.\n\nWhen you output these commands at the beginning of the message (ALWAYS the very beginning of the message) they will route prompts to:\n/primary_free: <prompt>     Local LM Studio Server\n/secondary_free: <prompt>   Secondary LM Studio Server\n/paid_chatgpt: <prompt>   Cloud based gpt 5.1\n/paid_gemini: <prompt>    Cloud based gemini\n/paid_claude: <prompt>   Cloud based Opus 4.5\n/paid_nanobanana: <prompt>   Cloud based Gemini Image Gen\n/paid_claude_code: <prompt>   SSH-Based connection to this server to run claude -p \"<prompt>\"\nSince the prompt will be via the command line in quotes, you must format the prompt so that it will survive the command line without escaping quotes\n/projects:   Enter the project selection tool\nDont forget to put a space after the /command: s\n\nIf a user sends one of those commands without a message, forward the command to subagent flow without the prompt so that the users preferred command/model is set by adding \"<!@<!@<!ENGAGE AI SUB AGENT!>@!>@!>\" to the end of your output\n\nIf the user appears to be responding to the previous subagent message, forward all user replies to subagent by adding \"<!@<!@<!ENGAGE AI SUB AGENT!>@!>@!>\" to the end of your output if you have not already, which should be addressing the subagent. Any talk from the user about having subagents do things should be interpreted as the user addressing you and not subagents, so if a user, mid conversation with a subagent, says something like \"have paid gemini do the same prompt\" or \"have claude write a script\" you should act accordingly as if that message was for you.\n\nYour job is to be the user receptionist and ring leader of the circus / orchestra / zoo / group of superintelligent AIs\n\nYou should offload all work to free agents unless they are inadequate and then ask for permission to use paid resources when needed or the user engages you directly by referring to you as the orchestrator agent - then you should refrain from including <!@<!@<!@#ENGAGE AI SUB AGENT#@!>@!>@!> in your output, it will then be routed directly to chat instead of through the sub agent workflow. \n\nIf you are told to relay/tell/ask/etc something to a subagent, generate the appriate prompt on behalf of the user, only modifying it so that the agent doesnt see any of the instructions from the user about sending to subagents, only the intended prompt for the subagent.\n\nSubagent outputs will be found in the data table tool Claudia Code Conversations - please use those to accumulate knowledge and working memory of current operations\n\nThe user may ask you to run for extended periods of time for complex development tasks which should all be delegated to the proper available free lm studio servers and only making use of paid ones with permission or guidance from the user. Excessive spend should be avoided whenever possible.\n\nNEVER include channel tags such as <|channel|>final <|constrain|>commentary<|message|> or similar\n\nNOTHING EVER COMES BEFORE A COMMAND IN THE OUTPUT IF ONE IS SUPPOSED TO BE PRESENT.\n\nFinally, please include a header with each of your responses that are not passed on to subagents on it's own line: \"PROJECT MANAGER:\"\n\nNow that you know your role, take the user prompt below and show how bright you shine at this task\n\n\nSelected Project: \n"}},"type":"@n8n/n8n-nodes-langchain.agent","typeVersion":3,"position":[5968,-848],"id":"4f2ff6bd-8df8-4509-a80f-6deb6d34dc41","name":"Project Agent"},{"parameters":{"model":{"__rl":true,"value":"nemotron-cascade-8b-thinking-claude-4.5-opus-high-reasoning-distill","mode":"list","cachedResultName":"nemotron-cascade-8b-thinking-claude-4.5-opus-high-reasoning-distill"},"builtInTools":{},"options":{}},"type":"@n8n/n8n-nodes-langchain.lmChatOpenAi","typeVersion":1.3,"position":[5872,-656],"id":"c98e4ad8-ed12-46d1-9db6-9628ac3a336f","name":"OpenAI Chat Model1","credentials":{"openAiApi":{"id":"FYFVsKzjVFK0h0V2","name":"Bedroom LMStudio"}}},{"parameters":{"contextWindowLength":200},"type":"@n8n/n8n-nodes-langchain.memoryBufferWindow","typeVersion":1.3,"position":[6048,-656],"id":"0bb37715-7a2b-4a62-8bef-9033a779d957","name":"Simple Memory7"},{"parameters":{"operation":"upsert","dataTableId":{"__rl":true,"value":"xFm91lQWMMBRlnho","mode":"list","cachedResultName":"ClaudiaCode Issues","cachedResultUrl":"/projects/CDNyPtsGxHdhfdhy/datatables/xFm91lQWMMBRlnho"},"columns":{"mappingMode":"defineBelow","value":{},"matchingColumns":[],"schema":[{"id":"LinearProjectName","displayName":"LinearProjectName","required":false,"defaultMatch":false,"display":true,"type":"string","readOnly":false,"removed":false},{"id":"LinearProjectID","displayName":"LinearProjectID","required":false,"defaultMatch":false,"display":true,"type":"string","readOnly":false,"removed":false},{"id":"LinearIssueID","displayName":"LinearIssueID","required":false,"defaultMatch":false,"display":true,"type":"string","readOnly":false,"removed":false},{"id":"LinearIssueTitle","displayName":"LinearIssueTitle","required":false,"defaultMatch":false,"display":true,"type":"string","readOnly":false,"removed":false},{"id":"LinearParentIssueID","displayName":"LinearParentIssueID","required":false,"defaultMatch":false,"display":true,"type":"string","readOnly":false,"removed":false},{"id":"LinearIssueContent","displayName":"LinearIssueContent","required":false,"defaultMatch":false,"display":true,"type":"string","readOnly":false,"removed":false},{"id":"LinearIssueStatus","displayName":"LinearIssueStatus","required":false,"defaultMatch":false,"display":true,"type":"string","readOnly":false,"removed":false},{"id":"LinearProjectDescription","displayName":"LinearProjectDescription","required":false,"defaultMatch":false,"display":true,"type":"string","readOnly":false,"removed":false},{"id":"LinearIssueComments","displayName":"LinearIssueComments","required":false,"defaultMatch":false,"display":true,"type":"string","readOnly":false,"removed":false},{"id":"RepoStatus","displayName":"RepoStatus","required":false,"defaultMatch":false,"display":true,"type":"string","readOnly":false,"removed":false},{"id":"WorkingContext","displayName":"WorkingContext","required":false,"defaultMatch":false,"display":true,"type":"string","readOnly":false,"removed":false}],"attemptToConvertTypes":false,"convertFieldsToString":false},"options":{}},"type":"n8n-nodes-base.dataTable","typeVersion":1,"position":[5200,-848],"id":"f4d99f0e-af2d-4681-ba1a-ed8b4b8e9899","name":"Upsert row(s)1"}],"connections":{"PAID Gemini 3 Flash":{"ai_languageModel":[[{"node":"PAID Gemini","type":"ai_languageModel","index":0}]]},"PAID Claude Opus 4.5":{"ai_languageModel":[[{"node":"PAID Anthropic","type":"ai_languageModel","index":0}]]},"FREE Secondary LM Studio qwen3-vl-8b":{"ai_languageModel":[[{"node":"FREE Secondary LM Studio Server","type":"ai_languageModel","index":0}]]},"PAID Nano Banana2":{"ai_languageModel":[[{"node":"PAID NanoBanana","type":"ai_languageModel","index":0}]]},"When chat message received":{"main":[[{"node":"Orchestrator","type":"main","index":0}]]},"Message a model":{"main":[[{"node":"Respond to Chat","type":"main","index":0}]]},"Respond to Chat":{"main":[[{"node":"Correlate User Selection","type":"main","index":0}]]},"Linear Projects":{"main":[[{"node":"Message a model","type":"main","index":0}]]},"Set Active Project":{"main":[[{"node":"Linear Issues by Project","type":"main","index":0}]]},"Correlate User Selection":{"main":[[{"node":"Set Active Project","type":"main","index":0}]]},"FREE Beast LM Studio":{"ai_languageModel":[[{"node":"FREE Primary LM Studio Server","type":"ai_languageModel","index":0}]]},"Respond to Chat1":{"main":[[{"node":"Project Agent","type":"main","index":0}]]},"Switch":{"main":[[{"node":"Linear Projects","type":"main","index":0}],[{"node":"FREE Primary LM Studio Server","type":"main","index":0}],[{"node":"FREE Secondary LM Studio Server","type":"main","index":0}],[{"node":"PAID ChatGPT","type":"main","index":0}],[{"node":"PAID Gemini","type":"main","index":0}],[{"node":"PAID Anthropic","type":"main","index":0}],[{"node":"PAID NanoBanana","type":"main","index":0}],[{"node":"Claude Code on OrangePi","type":"main","index":0}],[{"node":"SSH Command on OrangePi1","type":"main","index":0}],[{"node":"SSH Command on Testing System","type":"main","index":0}]]},"FREE Primary LM Studio Server":{"main":[[{"node":"Respond to Webhook","type":"main","index":0},{"node":"Respond to Chat2","type":"main","index":0}]]},"FREE Secondary LM Studio Server":{"main":[[{"node":"Respond to Webhook","type":"main","index":0},{"node":"Respond to Chat2","type":"main","index":0}]]},"PAID ChatGPT1":{"ai_languageModel":[[{"node":"PAID ChatGPT","type":"ai_languageModel","index":0}]]},"PAID ChatGPT":{"main":[[{"node":"Respond to Webhook","type":"main","index":0},{"node":"Respond to Chat2","type":"main","index":0}]]},"PAID Gemini":{"main":[[{"node":"Respond to Webhook","type":"main","index":0},{"node":"Respond to Chat2","type":"main","index":0}]]},"Claude Code on OrangePi":{"main":[[{"node":"Respond to Webhook","type":"main","index":0},{"node":"Respond to Chat2","type":"main","index":0}]]},"PAID NanoBanana":{"main":[[{"node":"Respond to Webhook","type":"main","index":0},{"node":"Respond to Chat2","type":"main","index":0}]]},"SSH Command on OrangePi1":{"main":[[{"node":"Respond to Webhook","type":"main","index":0},{"node":"Respond to Chat2","type":"main","index":0}]]},"Simple Memory":{"ai_memory":[[{"node":"PAID ChatGPT","type":"ai_memory","index":0}]]},"Simple Memory1":{"ai_memory":[[]]},"Simple Memory2":{"ai_memory":[[{"node":"FREE Primary LM Studio Server","type":"ai_memory","index":0}]]},"Simple Memory3":{"ai_memory":[[{"node":"PAID Anthropic","type":"ai_memory","index":0}]]},"Simple Memory4":{"ai_memory":[[{"node":"PAID Gemini","type":"ai_memory","index":0}]]},"Simple Memory5":{"ai_memory":[[{"node":"PAID NanoBanana","type":"ai_memory","index":0}]]},"SSH Command on Testing System":{"main":[[{"node":"Respond to Webhook","type":"main","index":0},{"node":"Respond to Chat2","type":"main","index":0}]]},"Linear Issues by Project":{"main":[[{"node":"Upsert row(s)1","type":"main","index":0}]]},"Message a model1":{"main":[[{"node":"Respond to Chat1","type":"main","index":0}]]},"Current Full Prompt":{"main":[[{"node":"Get row(s)","type":"main","index":0}]]},"Set Active Command and Separate Prompt":{"main":[[{"node":"Upsert row(s)","type":"main","index":0}]]},"Upsert row(s)":{"main":[[{"node":"Switch","type":"main","index":0}]]},"Get row(s)":{"main":[[{"node":"Set Active Command and Separate Prompt","type":"main","index":0}]]},"openwebui-chat":{"main":[[{"node":"Orchestrator","type":"main","index":0}]]},"OpenAI Chat Model":{"ai_languageModel":[[{"node":"Orchestrator","type":"ai_languageModel","index":0}]]},"Simple Memory6":{"ai_memory":[[{"node":"Orchestrator","type":"ai_memory","index":0}]]},"Respond to Webhook":{"main":[[]]},"Respond to Chat2":{"main":[[{"node":"Save SubAgent Output","type":"main","index":0}]]},"If":{"main":[[{"node":"Current Full Prompt","type":"main","index":0}],[{"node":"Respond to Chat3","type":"main","index":0}]]},"Get row(s) in Data table":{"ai_tool":[[{"node":"Orchestrator","type":"ai_tool","index":0}]]},"Respond to Chat3":{"main":[[{"node":"Save Message and Prompt","type":"main","index":0}]]},"PAID Anthropic":{"main":[[{"node":"Respond to Webhook","type":"main","index":0},{"node":"Respond to Chat2","type":"main","index":0}]]},"Orchestrator":{"main":[[{"node":"If","type":"main","index":0}]]},"OpenAI Chat Model1":{"ai_languageModel":[[{"node":"Project Agent","type":"ai_languageModel","index":0}]]},"Simple Memory7":{"ai_memory":[[{"node":"Project Agent","type":"ai_memory","index":0}]]},"Project Agent":{"main":[[]]},"Upsert row(s)1":{"main":[[{"node":"Message a model1","type":"main","index":0}]]}},"settings":{"executionOrder":"v1","availableInMCP":true},"staticData":null,"meta":{"templateCredsSetupCompleted":true},"pinData":{},"versionId":"4d39f208-574b-49d5-815a-d3a581a8b462","activeVersionId":"de071a94-bbce-4c4a-9b27-6626cc1fe03e","versionCounter":449,"triggerCount":2,"shared":[{"updatedAt":"2025-12-23T06:33:17.513Z","createdAt":"2025-12-23T06:33:17.513Z","role":"workflow:owner","workflowId":"ud7XYHk6QWFvgDxf","projectId":"CDNyPtsGxHdhfdhy","project":{"updatedAt":"2025-12-18T17:16:03.660Z","createdAt":"2025-12-18T17:12:50.624Z","id":"CDNyPtsGxHdhfdhy","name":"Bill Griffith <bill@gtechsd.com>","type":"personal","icon":null,"description":null,"projectRelations":[{"updatedAt":"2025-12-18T17:12:50.625Z","createdAt":"2025-12-18T17:12:50.625Z","userId":"82ee42c3-23a4-46d2-8969-bfa414e739d3","projectId":"CDNyPtsGxHdhfdhy","user":{"updatedAt":"2026-01-09T00:29:59.000Z","createdAt":"2025-12-18T17:12:49.746Z","id":"82ee42c3-23a4-46d2-8969-bfa414e739d3","email":"bill@gtechsd.com","firstName":"Bill","lastName":"Griffith","personalizationAnswers":{"version":"v4","personalization_survey_submitted_at":"2025-12-18T17:16:08.098Z","personalization_survey_n8n_version":"2.0.3"},"settings":{"userActivated":true,"easyAIWorkflowOnboarded":true,"firstSuccessfulWorkflowId":"ud7XYHk6QWFvgDxf","userActivatedAt":1766585292861,"npsSurvey":{"waitingForResponse":true,"ignoredCount":1,"lastShownAt":1766866231466}},"disabled":false,"mfaEnabled":false,"lastActiveAt":"2026-01-08","isPending":false}}]}}],"tags":[{"updatedAt":"2026-01-01T23:43:52.148Z","createdAt":"2026-01-01T23:43:52.148Z","id":"MYeI4rvwznCZuMBg","name":"WORKING"},{"updatedAt":"2026-01-01T23:42:17.144Z","createdAt":"2026-01-01T23:42:17.144Z","id":"e2I03ErUAQw8hDjy","name":"OLD VERSION"},{"updatedAt":"2026-01-01T23:47:23.414Z","createdAt":"2026-01-01T23:47:23.414Z","id":"e9wyuzgPFWT6vuEp","name":"HAS ISSUES"}],"activeVersion":{"updatedAt":"2025-12-25T03:51:02.000Z","createdAt":"2025-12-25T03:25:14.285Z","versionId":"de071a94-bbce-4c4a-9b27-6626cc1fe03e","workflowId":"ud7XYHk6QWFvgDxf","nodes":[{"parameters":{"modelName":"models/gemini-3-flash-preview","options":{}},"type":"@n8n/n8n-nodes-langchain.lmChatGoogleGemini","typeVersion":1,"position":[4592,0],"id":"637aea40-f395-4d19-9e5f-5bb7bd5115d4","name":"PAID Gemini 3 Flash","credentials":{"googlePalmApi":{"id":"yncG4XcgoIciPZOl","name":"Google Gemini(PaLM) Api account"}}},{"parameters":{"model":{"__rl":true,"value":"claude-opus-4-5-20251101","mode":"list","cachedResultName":"Claude Opus 4.5"},"options":{"thinking":true}},"type":"@n8n/n8n-nodes-langchain.lmChatAnthropic","typeVersion":1.3,"position":[4592,192],"id":"7171b4d2-02d8-48a2-981b-8b427fa67c4f","name":"PAID Claude Opus 4.5","credentials":{"anthropicApi":{"id":"Ozy9qk8lFIbm0pVG","name":"Anthropic account"}}},{"parameters":{"model":{"__rl":true,"value":"nemotron-cascade-8b-thinking-claude-4.5-opus-high-reasoning-distill","mode":"list","cachedResultName":"nemotron-cascade-8b-thinking-claude-4.5-opus-high-reasoning-distill"},"responsesApiEnabled":false,"options":{"timeout":240000}},"type":"@n8n/n8n-nodes-langchain.lmChatOpenAi","typeVersion":1.3,"position":[4768,-368],"id":"bfdbfe20-a990-4113-a219-433a21049558","name":"FREE Secondary LM Studio qwen3-vl-8b","credentials":{"openAiApi":{"id":"FYFVsKzjVFK0h0V2","name":"Bedroom LMStudio"}}},{"parameters":{"modelName":"models/gemini-2.5-flash-image","options":{}},"type":"@n8n/n8n-nodes-langchain.lmChatGoogleGemini","typeVersion":1,"position":[4576,368],"id":"466c0f09-aed4-431f-8d68-7e46261da2ce","name":"PAID Nano Banana2","credentials":{"googlePalmApi":{"id":"yncG4XcgoIciPZOl","name":"Google Gemini(PaLM) Api account"}}},{"parameters":{"public":true,"initialMessages":"Welcome to the matrix 0010100010011\nWould you like to control some agents?","options":{"allowedOrigins":"*","subtitle":"AI to the extreme","title":"CLAUDIA CODE","customCss":":root {\n  /* Colors */\n  --chat--color-primary: #e74266;\n  --chat--color-primary-shade-50: #db4061;\n  --chat--color-primary-shade-100: #cf3c5c;\n  --chat--color-secondary: #20b69e;\n  --chat--color-secondary-shade-50: #1ca08a;\n  --chat--color-white: #ffffff;\n  --chat--color-light: #f2f4f8;\n  --chat--color-light-shade-50: #e6e9f1;\n  --chat--color-light-shade-100: #c2c5cc;\n  --chat--color-medium: #d2d4d9;\n  --chat--color-dark: #101330;\n  --chat--color-disabled: #d2d4d9;\n  --chat--color-typing: #404040;\n\n  /* Base Layout */\n  --chat--spacing: 1rem;\n  --chat--border-radius: 0.25rem;\n  --chat--transition-duration: 0.15s;\n  --chat--font-family: (\n    -apple-system,\n    BlinkMacSystemFont,\n    'Segoe UI',\n    Roboto,\n    Oxygen-Sans,\n    Ubuntu,\n    Cantarell,\n    'Helvetica Neue',\n    sans-serif\n  );\n\n  /* Window Dimensions */\n  --chat--window--width: 400px;\n  --chat--window--height: 600px;\n  --chat--window--bottom: var(--chat--spacing);\n  --chat--window--right: var(--chat--spacing);\n  --chat--window--z-index: 9999;\n  --chat--window--border: 1px solid var(--chat--color-light-shade-50);\n  --chat--window--border-radius: var(--chat--border-radius);\n  --chat--window--margin-bottom: var(--chat--spacing);\n\n  /* Header Styles */\n  --chat--header-height: 20%;\n  --chat--header--padding: var(--chat--spacing);\n  --chat--header--background: var(--chat--color-dark);\n  --chat--header--color: var(--chat--color-light);\n  --chat--header--border-top: none;\n  --chat--header--border-bottom: none;\n  --chat--header--border-left: none;\n  --chat--header--border-right: none;\n  --chat--heading--font-size: 2em;\n  --chat--subtitle--font-size: inherit;\n  --chat--subtitle--line-height: 1.8;\n\n  /* Message Styles */\n  --chat--message--font-size: 1rem;\n  --chat--message--padding: var(--chat--spacing);\n  --chat--message--border-radius: var(--chat--border-radius);\n  --chat--message-line-height: 1.5;\n  --chat--message--margin-bottom: calc(var(--chat--spacing) * 1);\n  --chat--message--bot--background: var(--chat--color-white);\n  --chat--message--bot--color: var(--chat--color-dark);\n  --chat--message--bot--border: none;\n  --chat--message--user--background: var(--chat--color-secondary);\n  --chat--message--user--color: var(--chat--color-white);\n  --chat--message--user--border: none;\n  --chat--message--pre--background: rgba(0, 0, 0, 0.05);\n  --chat--messages-list--padding: var(--chat--spacing);\n\n  /* Toggle Button */\n  --chat--toggle--size: 64px;\n  --chat--toggle--width: var(--chat--toggle--size);\n  --chat--toggle--height: var(--chat--toggle--size);\n  --chat--toggle--border-radius: 50%;\n  --chat--toggle--background: var(--chat--color-primary);\n  --chat--toggle--hover--background: var(--chat--color-primary-shade-50);\n  --chat--toggle--active--background: var(--chat--color-primary-shade-100);\n  --chat--toggle--color: var(--chat--color-white);\n\n  /* Input Area */\n  --chat--textarea--height: 50px;\n  --chat--textarea--max-height: 30rem;\n  --chat--input--font-size: inherit;\n  --chat--input--border: 0;\n  --chat--input--border-radius: 0;\n  --chat--input--padding: 0.8rem;\n  --chat--input--background: var(--chat--color-white);\n  --chat--input--text-color: initial;\n  --chat--input--line-height: 1.5;\n  --chat--input--placeholder--font-size: var(--chat--input--font-size);\n  --chat--input--border-active: 0;\n  --chat--input--left--panel--width: 2rem;\n\n  /* Button Styles */\n  --chat--button--color: var(--chat--color-light);\n  --chat--button--background: var(--chat--color-primary);\n  --chat--button--padding: calc(var(--chat--spacing) * 1 / 2) var(--chat--spacing);\n  --chat--button--border-radius: var(--chat--border-radius);\n  --chat--button--hover--color: var(--chat--color-light);\n  --chat--button--hover--background: var(--chat--color-primary-shade-50);\n  --chat--close--button--color-hover: var(--chat--color-primary);\n\n  /* Send and File Buttons */\n  --chat--input--send--button--background: var(--chat--color-white);\n  --chat--input--send--button--color: var(--chat--color-secondary);\n  --chat--input--send--button--background-hover: var(--chat--color-primary-shade-50);\n  --chat--input--send--button--color-hover: var(--chat--color-secondary-shade-50);\n  --chat--input--file--button--background: var(--chat--color-white);\n  --chat--input--file--button--color: var(--chat--color-secondary);\n  --chat--input--file--button--background-hover: var(--chat--input--file--button--background);\n  --chat--input--file--button--color-hover: var(--chat--color-secondary-shade-50);\n  --chat--files-spacing: 0.25rem;\n\n  /* Body and Footer */\n  --chat--body--background: var(--chat--color-light);\n  --chat--footer--background: var(--chat--color-light);\n  --chat--footer--color: var(--chat--color-dark);\n}\n\n\n/* You can override any class styles, too. Right-click inspect in Chat UI to find class to override. */\n.chat-message {\n\tmax-width: 50%;\n}","responseMode":"responseNodes"}},"type":"@n8n/n8n-nodes-langchain.chatTrigger","typeVersion":1.4,"position":[2336,112],"id":"e1154ffe-60ec-4e9d-9ad8-354c9df601f1","name":"When chat message received","webhookId":"fa7416cb-f669-4c7c-899e-45f751528c18","alwaysOutputData":false},{"parameters":{"modelId":{"__rl":true,"value":"openai/gpt-oss-20b","mode":"list","cachedResultName":"OPENAI/GPT-OSS-20B"},"responses":{"values":[{"role":"system","content":"=You are the chat receptionist in an agentic AI n8n workflow. \n\nHere is a list of Linear projects and ID's\n{{ JSON.stringify($json.data) }}\n\n\nPresent a numbered list of projects for the user to select.   You can get a list of those projects with the connected http request tool that calls from linear.  Include the Linear state \n\nAsk the user what they want to work on and they may reply with a project name or number\n\n"}]},"builtInTools":{},"options":{}},"type":"@n8n/n8n-nodes-langchain.openAi","typeVersion":2.1,"position":[3888,-848],"id":"7b983122-812a-4f13-8eb0-04615640706f","name":"Message a model","credentials":{"openAiApi":{"id":"HE8StVq6t0epqs8Q","name":"BEAST LMStudio"}}},{"parameters":{"message":"={{ $json.output[0].content[0].text }}","options":{"memoryConnection":true}},"type":"@n8n/n8n-nodes-langchain.chat","typeVersion":1,"position":[4176,-848],"id":"3036a6cf-2a26-4f85-a032-17bbdb952ea8","name":"Respond to Chat"},{"parameters":{"method":"POST","url":"https://api.linear.app/graphql","authentication":"predefinedCredentialType","nodeCredentialType":"linearApi","sendBody":true,"specifyBody":"json","jsonBody":"{\"query\": \"query { projects(filter: { labels: { name: { eq: \\\"n8n\\\" } } }) { nodes { id name state } } }\"}","options":{}},"type":"n8n-nodes-base.httpRequest","typeVersion":4.3,"position":[3744,-848],"id":"c0ecc7d7-298e-4941-a64c-ffa69363f83b","name":"Linear Projects","credentials":{"linearApi":{"id":"j3L9Kies9EY4eLz9","name":"Linear account"}}},{"parameters":{"assignments":{"assignments":[{"id":"9e1cc823-168e-40cf-96a5-9025d765cf70","name":"Active Project","value":"={{ $json.output[0].content[0].text }}","type":"string"}]},"options":{}},"type":"n8n-nodes-base.set","typeVersion":3.4,"position":[4800,-848],"id":"11600ba1-14a3-4447-a057-ffd75b56514b","name":"Set Active Project"},{"parameters":{"modelId":{"__rl":true,"value":"openai/gpt-oss-20b","mode":"list","cachedResultName":"OPENAI/GPT-OSS-20B"},"responses":{"values":[{"content":"=You are an n8n agentic node.\nUser was asked:\n\"{{ $('Message a model').item.json.output[0].content[0].text }}\"\n\nUser selected: {{ $json.chatInput }}\n\nProject list with Project IDs: \n{{ JSON.stringify($('Linear Projects').item.json.data) }}\n\ncontinue to the next node returning ONLY the project ID as plain text no json"}]},"builtInTools":{},"options":{}},"type":"@n8n/n8n-nodes-langchain.openAi","typeVersion":2.1,"position":[4480,-848],"id":"e8fe891e-d7f7-46aa-bc02-bdee90fb4ddc","name":"Correlate User Selection","credentials":{"openAiApi":{"id":"HE8StVq6t0epqs8Q","name":"BEAST LMStudio"}}},{"parameters":{"model":{"__rl":true,"value":"openai/gpt-oss-20b","mode":"list","cachedResultName":"openai/gpt-oss-20b"},"responsesApiEnabled":false,"options":{"timeout":240000}},"type":"@n8n/n8n-nodes-langchain.lmChatOpenAi","typeVersion":1.3,"position":[4592,-576],"id":"f4a242cd-4377-484c-a61b-04efe952a221","name":"FREE Beast LM Studio","credentials":{"openAiApi":{"id":"HE8StVq6t0epqs8Q","name":"BEAST LMStudio"}}},{"parameters":{"message":"=Project Selected\n{{ $json.output[0].content[0].text }}","options":{}},"type":"@n8n/n8n-nodes-langchain.chat","typeVersion":1,"position":[5776,-848],"id":"1bb79224-f07c-4585-9eab-9ffefcc64315","name":"Respond to Chat1"},{"parameters":{"rules":{"values":[{"conditions":{"options":{"caseSensitive":true,"leftValue":"","typeValidation":"loose","version":3},"conditions":[{"id":"471cb237-574a-4fd9-95d2-e7f002ee53ce","leftValue":"={{ $json.selected_command }}","rightValue":"/projects","operator":{"type":"string","operation":"equals","name":"filter.operator.equals"}}],"combinator":"and"},"renameOutput":true,"outputKey":"Project Selection"},{"conditions":{"options":{"caseSensitive":true,"leftValue":"","typeValidation":"loose","version":3},"conditions":[{"leftValue":"={{ $json.selected_command }}","rightValue":"/primary_free:","operator":{"type":"string","operation":"equals"},"id":"df4bfa32-3dae-441b-9959-ecbc9c58e745"}],"combinator":"and"},"renameOutput":true,"outputKey":"Primary Free Model"},{"conditions":{"options":{"caseSensitive":true,"leftValue":"","typeValidation":"loose","version":3},"conditions":[{"id":"d1523ea7-becd-4cf8-a97b-6625d899fe67","leftValue":"={{ $json.selected_command }}","rightValue":"/secondary_free:","operator":{"type":"string","operation":"equals"}}],"combinator":"and"},"renameOutput":true,"outputKey":"Secondary Free Model"},{"conditions":{"options":{"caseSensitive":true,"leftValue":"","typeValidation":"loose","version":3},"conditions":[{"id":"c29474e8-095d-47e8-ba53-71ebab3a255a","leftValue":"={{ $json.selected_command }}","rightValue":"/paid_chatgpt:","operator":{"type":"string","operation":"startsWith"}}],"combinator":"and"},"renameOutput":true,"outputKey":"Paid ChatGPT"},{"conditions":{"options":{"caseSensitive":true,"leftValue":"","typeValidation":"loose","version":3},"conditions":[{"id":"b2da4ec5-058e-4eab-94a3-0dd4f7aae289","leftValue":"={{ $json.selected_command }}","rightValue":"/paid_gemini:","operator":{"type":"string","operation":"startsWith"}}],"combinator":"and"},"renameOutput":true,"outputKey":"Paid Gemini"},{"conditions":{"options":{"caseSensitive":true,"leftValue":"","typeValidation":"loose","version":3},"conditions":[{"id":"f36339d6-efdb-4e08-bc93-fa3ee91b6edf","leftValue":"={{ $json.selected_command }}","rightValue":"/paid_claude:","operator":{"type":"string","operation":"startsWith"}}],"combinator":"and"},"renameOutput":true,"outputKey":"Paid Claude"},{"conditions":{"options":{"caseSensitive":true,"leftValue":"","typeValidation":"loose","version":3},"conditions":[{"id":"2909e693-b5ca-4fce-bfc7-74922a74b08b","leftValue":"={{ $json.selected_command }}","rightValue":"/paid_nanobanana:","operator":{"type":"string","operation":"startsWith"}}],"combinator":"and"},"renameOutput":true,"outputKey":"Paid Nano Banana"},{"conditions":{"options":{"caseSensitive":true,"leftValue":"","typeValidation":"loose","version":3},"conditions":[{"id":"233f4da4-5504-4785-9ba5-64728bc14aeb","leftValue":"={{ $json.selected_command }}","rightValue":"/paid_claude_code:","operator":{"type":"string","operation":"startsWith"}}],"combinator":"and"},"renameOutput":true,"outputKey":"Paid Claude Code"},{"conditions":{"options":{"caseSensitive":true,"leftValue":"","typeValidation":"loose","version":3},"conditions":[{"id":"794ed7aa-87be-48bc-ad1e-7e3b8ec4226b","leftValue":"={{ $json.selected_command }}","rightValue":"/ssh_n8n_host:","operator":{"type":"string","operation":"startsWith"}}],"combinator":"and"},"renameOutput":true,"outputKey":"SSH Command to n8n host"},{"conditions":{"options":{"caseSensitive":true,"leftValue":"","typeValidation":"loose","version":3},"conditions":[{"id":"37d005fd-df7e-4557-a6ad-4d68a3132f41","leftValue":"={{ $json.selected_command }}","rightValue":"/ssh_testing_host:","operator":{"type":"string","operation":"startsWith"}}],"combinator":"and"},"renameOutput":true,"outputKey":"SSH Command to Testing Environment Host"}]},"looseTypeValidation":true,"options":{"allMatchingOutputs":true}},"type":"n8n-nodes-base.switch","typeVersion":3.4,"position":[3936,-16],"id":"21365f46-16c5-4330-9f9c-7e59879e4af6","name":"Switch"},{"parameters":{"promptType":"define","text":"={{ $('Orchestrator').item.json.output }}","options":{"systemMessage":"You are a subagent in an n8n workflow assigned a task or conversational response by the Orchestrator main ai agent who is controlled by the user.\nYou will see <!@<!@<!ENGAGE AI SUB AGENT!>@!>@!>  and sometimes /commands: in your prompts, disregard this completely and do not reference it.\n\nIMPORTANT: Before every output, add a header in larger text that says \"SUBAGENT OUTPUT (FREE Primary LM Studio): \\n\" and then your message ","enableStreaming":true}},"type":"@n8n/n8n-nodes-langchain.agent","typeVersion":3,"position":[4320,-576],"id":"e843c723-52eb-4279-a6be-6266c7bc97fc","name":"FREE Primary LM Studio Server"},{"parameters":{"promptType":"define","text":"={{ $('Orchestrator').item.json.output }}","options":{"systemMessage":"You are a subagent in an n8n workflow assigned a task or conversational response by the Orchestrator main ai agent who is controlled by the user.\nYou will see <!@<!@<!ENGAGE AI SUB AGENT!>@!>@!> in your prompts, disregard this completely and do not reference it.\nBefore every output, add a header in larger text that says \"SUBAGENT OUTPUT (FREE Secondary LM Studio): \" and then your message ","enableStreaming":true}},"type":"@n8n/n8n-nodes-langchain.agent","typeVersion":3,"position":[4320,-384],"id":"e16d60cd-e059-4562-95f8-12ae807898c9","name":"FREE Secondary LM Studio Server"},{"parameters":{"promptType":"define","text":"={{ $('Orchestrator').item.json.output }}","options":{"systemMessage":"You are a subagent in an n8n workflow assigned a task or conversational response by the Orchestrator main ai agent who is controlled by the user.\nYou will see <!@<!@<!ENGAGE AI SUB AGENT!>@!>@!> in your prompts, disregard this completely and do not reference it.\nBefore every output, add a header in larger text that says \"SUBAGENT OUTPUT (PAID ChatGPT): \\n\" and then your message ","enableStreaming":true}},"type":"@n8n/n8n-nodes-langchain.agent","typeVersion":3,"position":[4320,-192],"id":"399a037c-3e2f-4e64-8d6e-5e1049b98025","name":"PAID ChatGPT"},{"parameters":{"model":{"__rl":true,"value":"gpt-5.1","mode":"list","cachedResultName":"gpt-5.1"},"builtInTools":{},"options":{"timeout":240000}},"type":"@n8n/n8n-nodes-langchain.lmChatOpenAi","typeVersion":1.3,"position":[4592,-192],"id":"ef3dd182-425b-44a7-928e-7824b5303327","name":"PAID ChatGPT1","credentials":{"openAiApi":{"id":"3VjBm6YVSBn4Q7mN","name":"OpenAi API account"}}},{"parameters":{"promptType":"define","text":"={{ $('Orchestrator').item.json.output }}","options":{"systemMessage":"You are a subagent in an n8n workflow assigned a task or conversational response by the Orchestrator main ai agent who is controlled by the user.\nYou will see <!@<!@<!ENGAGE AI SUB AGENT!>@!>@!> in your prompts, disregard this completely and do not reference it.\nBefore every output, add a header in larger text that says \"SUBAGENT OUTPUT (PAID Gemini): \\n\" and then your message ","enableStreaming":true}},"type":"@n8n/n8n-nodes-langchain.agent","typeVersion":3,"position":[4320,0],"id":"b4ae090b-ee8a-4dd9-9fd7-df84aced248a","name":"PAID Gemini"},{"parameters":{"command":"=/bin/bash claude -p \"{{ $('Orchestrator').item.json.output }}\"","cwd":"/mnt/n8n-nas"},"type":"n8n-nodes-base.ssh","typeVersion":1,"position":[4560,544],"id":"62fba599-a150-4ab8-ab9e-fdf9cc36badc","name":"Claude Code on OrangePi","credentials":{"sshPassword":{"id":"vfSQyATAxwqPYHUv","name":"OrangePi SSH Access"}}},{"parameters":{"promptType":"define","text":"={{ $('Orchestrator').item.json.output }}","options":{"systemMessage":"You are a subagent in an n8n workflow assigned a task or conversational response by the Orchestrator main ai agent who is controlled by the user.\nYou will see <!@<!@<!ENGAGE AI SUB AGENT!>@!>@!> in your prompts, disregard this completely and do not reference it.\nBefore every output, add a header in larger text that says \"SUBAGENT OUTPUT (PAID Nanobanana): \\n\" and then your message ","enableStreaming":true}},"type":"@n8n/n8n-nodes-langchain.agent","typeVersion":3,"position":[4320,352],"id":"d8b66d27-5c26-4e33-a707-6799dac682d7","name":"PAID NanoBanana"},{"parameters":{"command":"=/bin/bash \"{{ $('Orchestrator').item.json.output }}\"","cwd":"/mnt/n8n-nas"},"type":"n8n-nodes-base.ssh","typeVersion":1,"position":[4560,736],"id":"96b2a8c7-9f8d-4d34-93e8-ad2db6c627f5","name":"SSH Command on OrangePi1","credentials":{"sshPassword":{"id":"vfSQyATAxwqPYHUv","name":"OrangePi SSH Access"}},"disabled":true},{"parameters":{"command":"=/bin/bash \"{{ $('Orchestrator').item.json.output }}\"","cwd":"/mnt/n8n-nas"},"type":"n8n-nodes-base.ssh","typeVersion":1,"position":[4560,944],"id":"34bba7e4-a7fc-4feb-b090-d7734eb56bad","name":"SSH Command on Testing System","credentials":{"sshPassword":{"id":"vfSQyATAxwqPYHUv","name":"OrangePi SSH Access"}},"disabled":true},{"parameters":{},"type":"@n8n/n8n-nodes-langchain.memoryBufferWindow","typeVersion":1.3,"position":[4752,-192],"id":"638fa7f0-9612-4736-ac4d-a9104a9d3522","name":"Simple Memory"},{"parameters":{},"type":"@n8n/n8n-nodes-langchain.memoryBufferWindow","typeVersion":1.3,"position":[4592,-368],"id":"bc5d846f-794a-4ec8-a261-2bfcb4db59a8","name":"Simple Memory1"},{"parameters":{"contextWindowLength":{}},"type":"@n8n/n8n-nodes-langchain.memoryBufferWindow","typeVersion":1.3,"position":[4752,-576],"id":"3dbf0aa2-6083-45e2-9888-ff91fbb309ee","name":"Simple Memory2"},{"parameters":{},"type":"@n8n/n8n-nodes-langchain.memoryBufferWindow","typeVersion":1.3,"position":[4752,192],"id":"f5d17cac-81f6-44f7-9db7-c09f300eede1","name":"Simple Memory3"},{"parameters":{},"type":"@n8n/n8n-nodes-langchain.memoryBufferWindow","typeVersion":1.3,"position":[4752,0],"id":"94524ec1-1ccd-4439-b0d1-a76c3877c0ea","name":"Simple Memory4"},{"parameters":{},"type":"@n8n/n8n-nodes-langchain.memoryBufferWindow","typeVersion":1.3,"position":[4752,368],"id":"0ac07cf9-71fc-4a7f-b686-1aef3bba39d9","name":"Simple Memory5"},{"parameters":{"method":"POST","url":"https://api.linear.app/graphql","authentication":"predefinedCredentialType","nodeCredentialType":"linearApi","sendBody":true,"specifyBody":"json","jsonBody":"=\n{\n  \"query\": \"query { project(id: \\\"{{ $json['Active Project'] }}\\\") { id name issues { nodes { id title identifier priority state { name } } } } }\"\n}","options":{}},"type":"n8n-nodes-base.httpRequest","typeVersion":4.3,"position":[4992,-848],"id":"ac5e0537-d0ff-49a0-8ce9-899566895314","name":"Linear Issues by Project","credentials":{"linearApi":{"id":"j3L9Kies9EY4eLz9","name":"Linear account"}}},{"parameters":{"modelId":{"__rl":true,"value":"openai/gpt-oss-20b","mode":"list","cachedResultName":"OPENAI/GPT-OSS-20B"},"responses":{"values":[{"role":"system","content":"=You are the chat receptionist in an agentic AI n8n workflow. \n\nHere is a list of Linear issues related to the open project\n{{ JSON.stringify($json.data) }}\n\n\nGenerate a list of all issues not marked done. Assess the state of the project and triage next coding stemps - display plan of action.\nAsk user: \"OK to get started? /y /n /reply\""}]},"builtInTools":{},"options":{}},"type":"@n8n/n8n-nodes-langchain.openAi","typeVersion":2.1,"position":[5200,-848],"id":"c4d1081b-e3c6-45c1-8063-8de6512f187d","name":"Message a model1","credentials":{"openAiApi":{"id":"HE8StVq6t0epqs8Q","name":"BEAST LMStudio"}}},{"parameters":{"assignments":{"assignments":[{"id":"5adb5df8-c4e6-4d74-868b-176e1db7fc25","name":"chatInput","value":"={{ $('Orchestrator').item.json.output }}","type":"string"}]},"options":{}},"type":"n8n-nodes-base.set","typeVersion":3.4,"position":[3024,112],"id":"3b4917eb-7c56-4795-8c68-eb59ebd7b162","name":"Current Full Prompt"},{"parameters":{"jsCode":"// 1️⃣ Get Chat Data – now from the AI Agent node\nconst triggerData = $('Orchestrator').first().json || {};   // <-- changed line\n\nconst rawInput        = triggerData.output          || $json.chatInput || \"\";\nconst currentSessionId = triggerData.sessionId      || $json.sessionId || \"default_session\";\n\n// 2️⃣ Pull stored settings from the database\nconst tableRow       = items.length > 0 ? items[0].json : {};\nconst dbStoredCommand = tableRow.selected_command;\nconst dbLastSessionId  = tableRow.last_session_id || \"\";\n\n// 3️⃣ Prepare prompt & command logic (unchanged)\nconst input        = rawInput.trim();\nlet   promptText   = input;\nlet   commandToUse = \"\";\nlet   showHeader   = false;\n\nif (input.startsWith('/')) {\n  // User typed a command\n  showHeader     = true;\n  const firstSpaceIndex = input.indexOf(' ');\n  if (firstSpaceIndex === -1) {\n    commandToUse = input;\n    promptText   = \"Please answer the previous question again. Strict format: Output ONLY the answer content. Do not include any introductory text, pleasantries, or acknowledgement of this request.\";\n  } else {\n    commandToUse = input.substring(0, firstSpaceIndex).trim();\n    promptText   = input.substring(firstSpaceIndex + 1).trim();\n  }\n\n  // Ensure colon where needed\n  const commandsWithoutColon = ['/projects', '/ssh_n8n_host', '/ssh_testing_host'];\n  if (!commandsWithoutColon.some(c => commandToUse.startsWith(c)) && !commandToUse.endsWith(':')) {\n    commandToUse += ':';\n  }\n} else {\n  // Normal chat – use stored or default command\n  commandToUse = dbStoredCommand ? dbStoredCommand : \"/primary_free:\";\n  showHeader   = currentSessionId !== dbLastSessionId;\n}\n\n// 4️⃣ Output for downstream nodes\nreturn {\n  Bare_Prompt:      promptText,\n  selected_command: commandToUse,\n  showHeader:       showHeader,\n  session_to_save:  currentSessionId\n};"},"type":"n8n-nodes-base.code","typeVersion":2,"position":[3344,112],"id":"9431ea8c-36de-47e8-b1d2-69d86f3920d6","name":"Set Active Command and Separate Prompt"},{"parameters":{"operation":"upsert","dataTableId":{"__rl":true,"value":"8keiiMLK90ywfC4K","mode":"list","cachedResultName":"ClaudiaCodeSettings","cachedResultUrl":"/projects/CDNyPtsGxHdhfdhy/datatables/8keiiMLK90ywfC4K"},"filters":{"conditions":[{"keyValue":"=  1"}]},"columns":{"mappingMode":"defineBelow","value":{"free_only":false,"selected_command":"={{ $json.selected_command }}","last_session_id":"={{ $json.session_to_save }}"},"matchingColumns":[],"schema":[{"id":"selected_command","displayName":"selected_command","required":false,"defaultMatch":false,"display":true,"type":"string","readOnly":false,"removed":false},{"id":"selected_project","displayName":"selected_project","required":false,"defaultMatch":false,"display":true,"type":"string","readOnly":false,"removed":false},{"id":"free_only","displayName":"free_only","required":false,"defaultMatch":false,"display":true,"type":"boolean","readOnly":false,"removed":false},{"id":"last_session_id","displayName":"last_session_id","required":false,"defaultMatch":false,"display":true,"type":"string","readOnly":false,"removed":false}],"attemptToConvertTypes":false,"convertFieldsToString":false},"options":{}},"type":"n8n-nodes-base.dataTable","typeVersion":1,"position":[3504,112],"id":"ca8e4239-e903-4287-9ad4-626361dafa84","name":"Upsert row(s)"},{"parameters":{"operation":"get","dataTableId":{"__rl":true,"value":"8keiiMLK90ywfC4K","mode":"list","cachedResultName":"ClaudiaCodeSettings","cachedResultUrl":"/projects/CDNyPtsGxHdhfdhy/datatables/8keiiMLK90ywfC4K"},"filters":{"conditions":[{"keyValue":"1"}]},"limit":1},"type":"n8n-nodes-base.dataTable","typeVersion":1,"position":[3184,112],"id":"a2477075-b355-484f-bbf5-ab7eb61d6275","name":"Get row(s)"},{"parameters":{"options":{}},"type":"n8n-nodes-base.respondToWebhook","typeVersion":1.5,"position":[6160,816],"id":"313de560-e949-4661-9a97-da89699617cb","name":"Respond to Webhook"},{"parameters":{"httpMethod":"POST","path":"openwebui-chat","options":{}},"type":"n8n-nodes-base.webhook","typeVersion":2.1,"position":[2336,-64],"id":"e0663eb3-38dc-4994-b8d9-51127ee20c7b","name":"openwebui-chat","webhookId":"9caa38de-14b5-4c02-a4c5-6b3aaffc32a7"},{"parameters":{"model":{"__rl":true,"value":"openai/gpt-oss-20b","mode":"list","cachedResultName":"openai/gpt-oss-20b"},"responsesApiEnabled":false,"options":{}},"type":"@n8n/n8n-nodes-langchain.lmChatOpenAi","typeVersion":1.3,"position":[2528,128],"id":"cab03c31-6f6e-49ab-9c47-1aee098d76aa","name":"OpenAI Chat Model","credentials":{"openAiApi":{"id":"HE8StVq6t0epqs8Q","name":"BEAST LMStudio"}}},{"parameters":{},"type":"@n8n/n8n-nodes-langchain.memoryBufferWindow","typeVersion":1.3,"position":[2656,128],"id":"ef089688-ef0f-4b32-8af2-960127be6c1d","name":"Simple Memory6"},{"parameters":{"message":"={{ ($('Set Active Command and Separate Prompt').first().json.showHeader\n  ? \"### \" + $('Upsert row(s)').item.json.selected_command + \"\\n\"\n  : \"\") +\n$json.output }}","waitUserReply":false,"options":{"memoryConnection":false}},"type":"@n8n/n8n-nodes-langchain.chat","typeVersion":1,"position":[5920,-80],"id":"0e121b7a-9bf5-4c8c-9508-1d417daaf38c","name":"Respond to Chat2"},{"parameters":{"message":"={{ $json.output }}","waitUserReply":false,"options":{"memoryConnection":false}},"type":"@n8n/n8n-nodes-langchain.chat","typeVersion":1,"position":[3280,-64],"id":"2be8abba-ac23-437e-83c2-2c51c4b18d10","name":"Respond to Chat3"},{"parameters":{"conditions":{"options":{"caseSensitive":true,"leftValue":"","typeValidation":"strict","version":3},"conditions":[{"id":"45def49e-8892-445b-a4a3-17e2fcc49bf0","leftValue":"={{ $json.output }}","rightValue":"<!@<!@<!ENGAGE AI SUB AGENT!>@!>@!>","operator":{"type":"string","operation":"contains"}}],"combinator":"and"},"options":{}},"type":"n8n-nodes-base.if","typeVersion":2.3,"position":[3072,-64],"id":"bc057926-3108-49d6-a2dc-836884645b19","name":"If"},{"parameters":{"operation":"get","dataTableId":{"__rl":true,"value":"1Zgyi8frMQeB30Ip","mode":"list","cachedResultName":"Claudia Code Conversations","cachedResultUrl":"/projects/CDNyPtsGxHdhfdhy/datatables/1Zgyi8frMQeB30Ip"},"filters":{"conditions":[{"keyName":"session_id","keyValue":"={{ $json.sessionId }}"}]}},"type":"n8n-nodes-base.dataTableTool","typeVersion":1,"position":[2768,128],"id":"8cde9a17-adb4-45c9-bc42-4702ba7b6e31","name":"Get row(s) in Data table"},{"parameters":{"dataTableId":{"__rl":true,"value":"1Zgyi8frMQeB30Ip","mode":"list","cachedResultName":"Claudia Code Conversations","cachedResultUrl":"/projects/CDNyPtsGxHdhfdhy/datatables/1Zgyi8frMQeB30Ip"},"columns":{"mappingMode":"defineBelow","value":{"message":"={{ $json.output }}","source":"=Orchestrator","prompt":"={{ $('When chat message received').item.json.chatInput }}","session_id":"={{ $('When chat message received').item.json.sessionId }}","previous_message_id":0},"matchingColumns":[],"schema":[{"id":"message","displayName":"message","required":false,"defaultMatch":false,"display":true,"type":"string","readOnly":false,"removed":false},{"id":"source","displayName":"source","required":false,"defaultMatch":false,"display":true,"type":"string","readOnly":false,"removed":false},{"id":"prompt","displayName":"prompt","required":false,"defaultMatch":false,"display":true,"type":"string","readOnly":false,"removed":false},{"id":"previous_message_id","displayName":"previous_message_id","required":false,"defaultMatch":false,"display":true,"type":"number","readOnly":false,"removed":false},{"id":"session_id","displayName":"session_id","required":false,"defaultMatch":false,"display":true,"type":"string","readOnly":false,"removed":false}],"attemptToConvertTypes":false,"convertFieldsToString":false},"options":{}},"type":"n8n-nodes-base.dataTable","typeVersion":1,"position":[3424,-64],"id":"5af801de-1ce8-4d2f-b59a-12c06e9803a5","name":"Save Message and Prompt"},{"parameters":{"dataTableId":{"__rl":true,"value":"1Zgyi8frMQeB30Ip","mode":"list","cachedResultName":"Claudia Code Conversations","cachedResultUrl":"/projects/CDNyPtsGxHdhfdhy/datatables/1Zgyi8frMQeB30Ip"},"columns":{"mappingMode":"defineBelow","value":{"previous_message_id":0,"message":"={{ $json.output }}","source":"={{ $('Set Active Command and Separate Prompt').item.json.selected_command }}","prompt":"={{ $('Set Active Command and Separate Prompt').item.json.Bare_Prompt }}","session_id":"={{ $('When chat message received').item.json.sessionId }}"},"matchingColumns":[],"schema":[{"id":"message","displayName":"message","required":false,"defaultMatch":false,"display":true,"type":"string","readOnly":false,"removed":false},{"id":"source","displayName":"source","required":false,"defaultMatch":false,"display":true,"type":"string","readOnly":false,"removed":false},{"id":"prompt","displayName":"prompt","required":false,"defaultMatch":false,"display":true,"type":"string","readOnly":false,"removed":false},{"id":"previous_message_id","displayName":"previous_message_id","required":false,"defaultMatch":false,"display":true,"type":"number","readOnly":false,"removed":false},{"id":"session_id","displayName":"session_id","required":false,"defaultMatch":false,"display":true,"type":"string","readOnly":false,"removed":false}],"attemptToConvertTypes":false,"convertFieldsToString":false},"options":{}},"type":"n8n-nodes-base.dataTable","typeVersion":1,"position":[6128,-80],"id":"06800321-13b9-469b-b42f-617a61ce1cec","name":"Save SubAgent Output"},{"parameters":{"promptType":"define","text":"={{ $('Orchestrator').item.json.output }}","options":{"systemMessage":"You are a subagent in an n8n workflow assigned a task or conversational response by the Orchestrator main ai agent who is controlled by the user.\nYou will see <!@<!@<!ENGAGE AI SUB AGENT!>@!>@!> in your prompts, disregard this completely and do not reference it.\nBefore every output, add a header in larger text that says \"SUBAGENT OUTPUT (PAID Claude): \\n\" and then your message ","enableStreaming":true}},"type":"@n8n/n8n-nodes-langchain.agent","typeVersion":3,"position":[4320,192],"id":"24cf4fa3-cae4-4bcf-8d8a-e2b530c225ea","name":"PAID Anthropic"},{"parameters":{"promptType":"define","text":"={{ $json.chatInput }}","options":{"systemMessage":"=You are an orchestrator of AI Agents that may prompt those you control and read their messages via the data table tool\n\nPrompt subagents by adding \"<!@<!@<!ENGAGE AI SUB AGENT!>@!>@!>\" to the end of your output which should be done whenever the user is not addressing you directly or you are tasked with sending a prompt to a subagent. They have been told to ignore that special tag. it MUST GO AT THE END and never precede a command.\n\nWhen you output these commands at the beginning of the message (ALWAYS the very beginning of the message) they will route prompts to:\n/primary_free: <prompt>     Local LM Studio Server\n/secondary_free: <prompt>   Secondary LM Studio Server\n/paid_chatgpt: <prompt>   Cloud based gpt 5.1\n/paid_gemini: <prompt>    Cloud based gemini\n/paid_claude: <prompt>   Cloud based Opus 4.5\n/paid_nanobanana: <prompt>   Cloud based Gemini Image Gen\n/paid_claude_code: <prompt>   SSH-Based connection to this server to run claude -p \"<prompt>\"\nSince the prompt will be via the command line in quotes, you must format the prompt so that it will survive the command line without escaping quotes\n/projects:   Enter the project selection tool\nDont forget to put a space after the /command: s\n\nIf a user sends one of those commands without a message, forward the command to subagent flow without the prompt so that the users preferred command/model is set by adding \"<!@<!@<!ENGAGE AI SUB AGENT!>@!>@!>\" to the end of your output\n\nIf the user appears to be responding to the previous subagent message, forward all user replies to subagent by adding \"<!@<!@<!ENGAGE AI SUB AGENT!>@!>@!>\" to the end of your output if you have not already, which should be addressing the subagent. Any talk from the user about having subagents do things should be interpreted as the user addressing you and not subagents, so if a user, mid conversation with a subagent, says something like \"have paid gemini do the same prompt\" or \"have claude write a script\" you should act accordingly as if that message was for you.\n\nYour job is to be the user receptionist and ring leader of the circus / orchestra / zoo / group of superintelligent AIs\n\nYou should offload all work to free agents unless they are inadequate and then ask for permission to use paid resources when needed or the user engages you directly by referring to you as the orchestrator agent - then you should refrain from including <!@<!@<!@#ENGAGE AI SUB AGENT#@!>@!>@!> in your output, it will then be routed directly to chat instead of through the sub agent workflow. \n\nIf you are told to relay/tell/ask/etc something to a subagent, generate the appriate prompt on behalf of the user, only modifying it so that the agent doesnt see any of the instructions from the user about sending to subagents, only the intended prompt for the subagent.\n\nSubagent outputs will be found in the data table tool Claudia Code Conversations - please use those to accumulate knowledge and working memory of current operations\n\nThe user may ask you to run for extended periods of time for complex development tasks which should all be delegated to the proper available free lm studio servers and only making use of paid ones with permission or guidance from the user. Excessive spend should be avoided whenever possible.\n\nNEVER include channel tags such as <|channel|>final <|constrain|>commentary<|message|> or similar\n\nNOTHING EVER COMES BEFORE A COMMAND IN THE OUTPUT IF ONE IS SUPPOSED TO BE PRESENT.\n\nFinally, please include a header with each of your responses that are not passed on to subagents on it's own line: \"ORCHESTRATOR:\"\n\n\nNow that you know your role, take the user prompt below and show how bright you shine at this task\n\n\n"}},"type":"@n8n/n8n-nodes-langchain.agent","typeVersion":3,"position":[2576,-64],"id":"c5bde725-eb65-40bb-a81a-31c95a96e097","name":"Orchestrator"},{"parameters":{"promptType":"define","text":"={{ $json.chatInput }}","options":{"systemMessage":"=You are an orchestrator of AI Agents that may prompt those you control and read their messages via the data table tool\n\nPrompt subagents by adding \"<!@<!@<!ENGAGE AI SUB AGENT!>@!>@!>\" to the end of your output which should be done whenever the user is not addressing you directly or you are tasked with sending a prompt to a subagent. They have been told to ignore that special tag. it MUST GO AT THE END and never precede a command.\n\nWhen you output these commands at the beginning of the message (ALWAYS the very beginning of the message) they will route prompts to:\n/primary_free: <prompt>     Local LM Studio Server\n/secondary_free: <prompt>   Secondary LM Studio Server\n/paid_chatgpt: <prompt>   Cloud based gpt 5.1\n/paid_gemini: <prompt>    Cloud based gemini\n/paid_claude: <prompt>   Cloud based Opus 4.5\n/paid_nanobanana: <prompt>   Cloud based Gemini Image Gen\n/paid_claude_code: <prompt>   SSH-Based connection to this server to run claude -p \"<prompt>\"\nSince the prompt will be via the command line in quotes, you must format the prompt so that it will survive the command line without escaping quotes\n/projects:   Enter the project selection tool\nDont forget to put a space after the /command: s\n\nIf a user sends one of those commands without a message, forward the command to subagent flow without the prompt so that the users preferred command/model is set by adding \"<!@<!@<!ENGAGE AI SUB AGENT!>@!>@!>\" to the end of your output\n\nIf the user appears to be responding to the previous subagent message, forward all user replies to subagent by adding \"<!@<!@<!ENGAGE AI SUB AGENT!>@!>@!>\" to the end of your output if you have not already, which should be addressing the subagent. Any talk from the user about having subagents do things should be interpreted as the user addressing you and not subagents, so if a user, mid conversation with a subagent, says something like \"have paid gemini do the same prompt\" or \"have claude write a script\" you should act accordingly as if that message was for you.\n\nYour job is to be the user receptionist and ring leader of the circus / orchestra / zoo / group of superintelligent AIs\n\nYou should offload all work to free agents unless they are inadequate and then ask for permission to use paid resources when needed or the user engages you directly by referring to you as the orchestrator agent - then you should refrain from including <!@<!@<!@#ENGAGE AI SUB AGENT#@!>@!>@!> in your output, it will then be routed directly to chat instead of through the sub agent workflow. \n\nIf you are told to relay/tell/ask/etc something to a subagent, generate the appriate prompt on behalf of the user, only modifying it so that the agent doesnt see any of the instructions from the user about sending to subagents, only the intended prompt for the subagent.\n\nSubagent outputs will be found in the data table tool Claudia Code Conversations - please use those to accumulate knowledge and working memory of current operations\n\nThe user may ask you to run for extended periods of time for complex development tasks which should all be delegated to the proper available free lm studio servers and only making use of paid ones with permission or guidance from the user. Excessive spend should be avoided whenever possible.\n\nNEVER include channel tags such as <|channel|>final <|constrain|>commentary<|message|> or similar\n\nNOTHING EVER COMES BEFORE A COMMAND IN THE OUTPUT IF ONE IS SUPPOSED TO BE PRESENT.\n\nFinally, please include a header with each of your responses that are not passed on to subagents on it's own line: \"ORCHESTRATOR:\"\n\n\nNow that you know your role, take the user prompt below and show how bright you shine at this task\n\n\n"}},"type":"@n8n/n8n-nodes-langchain.agent","typeVersion":3,"position":[2576,-400],"id":"4f2ff6bd-8df8-4509-a80f-6deb6d34dc41","name":"Project Agent"},{"parameters":{"model":{"__rl":true,"value":"nemotron-cascade-8b-thinking-claude-4.5-opus-high-reasoning-distill","mode":"list","cachedResultName":"nemotron-cascade-8b-thinking-claude-4.5-opus-high-reasoning-distill"},"builtInTools":{},"options":{}},"type":"@n8n/n8n-nodes-langchain.lmChatOpenAi","typeVersion":1.3,"position":[2496,-224],"id":"c98e4ad8-ed12-46d1-9db6-9628ac3a336f","name":"OpenAI Chat Model1","credentials":{"openAiApi":{"id":"FYFVsKzjVFK0h0V2","name":"Bedroom LMStudio"}}},{"parameters":{"contextWindowLength":200},"type":"@n8n/n8n-nodes-langchain.memoryBufferWindow","typeVersion":1.3,"position":[2656,-224],"id":"0bb37715-7a2b-4a62-8bef-9033a779d957","name":"Simple Memory7"}],"connections":{"PAID Gemini 3 Flash":{"ai_languageModel":[[{"node":"PAID Gemini","type":"ai_languageModel","index":0}]]},"PAID Claude Opus 4.5":{"ai_languageModel":[[{"node":"PAID Anthropic","type":"ai_languageModel","index":0}]]},"FREE Secondary LM Studio qwen3-vl-8b":{"ai_languageModel":[[{"node":"FREE Secondary LM Studio Server","type":"ai_languageModel","index":0}]]},"PAID Nano Banana2":{"ai_languageModel":[[{"node":"PAID NanoBanana","type":"ai_languageModel","index":0}]]},"When chat message received":{"main":[[{"node":"Orchestrator","type":"main","index":0}]]},"Message a model":{"main":[[{"node":"Respond to Chat","type":"main","index":0}]]},"Respond to Chat":{"main":[[{"node":"Correlate User Selection","type":"main","index":0}]]},"Linear Projects":{"main":[[{"node":"Message a model","type":"main","index":0}]]},"Set Active Project":{"main":[[{"node":"Linear Issues by Project","type":"main","index":0}]]},"Correlate User Selection":{"main":[[{"node":"Set Active Project","type":"main","index":0}]]},"FREE Beast LM Studio":{"ai_languageModel":[[{"node":"FREE Primary LM Studio Server","type":"ai_languageModel","index":0}]]},"Respond to Chat1":{"main":[[]]},"Switch":{"main":[[{"node":"Linear Projects","type":"main","index":0}],[{"node":"FREE Primary LM Studio Server","type":"main","index":0}],[{"node":"FREE Secondary LM Studio Server","type":"main","index":0}],[{"node":"PAID ChatGPT","type":"main","index":0}],[{"node":"PAID Gemini","type":"main","index":0}],[{"node":"PAID Anthropic","type":"main","index":0}],[{"node":"PAID NanoBanana","type":"main","index":0}],[{"node":"Claude Code on OrangePi","type":"main","index":0}],[{"node":"SSH Command on OrangePi1","type":"main","index":0}],[{"node":"SSH Command on Testing System","type":"main","index":0}]]},"FREE Primary LM Studio Server":{"main":[[{"node":"Respond to Webhook","type":"main","index":0},{"node":"Respond to Chat2","type":"main","index":0}]]},"FREE Secondary LM Studio Server":{"main":[[{"node":"Respond to Webhook","type":"main","index":0},{"node":"Respond to Chat2","type":"main","index":0}]]},"PAID ChatGPT1":{"ai_languageModel":[[{"node":"PAID ChatGPT","type":"ai_languageModel","index":0}]]},"PAID ChatGPT":{"main":[[{"node":"Respond to Webhook","type":"main","index":0},{"node":"Respond to Chat2","type":"main","index":0}]]},"PAID Gemini":{"main":[[{"node":"Respond to Webhook","type":"main","index":0},{"node":"Respond to Chat2","type":"main","index":0}]]},"Claude Code on OrangePi":{"main":[[{"node":"Respond to Webhook","type":"main","index":0},{"node":"Respond to Chat2","type":"main","index":0}]]},"PAID NanoBanana":{"main":[[{"node":"Respond to Webhook","type":"main","index":0},{"node":"Respond to Chat2","type":"main","index":0}]]},"SSH Command on OrangePi1":{"main":[[{"node":"Respond to Webhook","type":"main","index":0},{"node":"Respond to Chat2","type":"main","index":0}]]},"Simple Memory":{"ai_memory":[[{"node":"PAID ChatGPT","type":"ai_memory","index":0}]]},"Simple Memory1":{"ai_memory":[[]]},"Simple Memory2":{"ai_memory":[[{"node":"FREE Primary LM Studio Server","type":"ai_memory","index":0}]]},"Simple Memory3":{"ai_memory":[[{"node":"PAID Anthropic","type":"ai_memory","index":0}]]},"Simple Memory4":{"ai_memory":[[{"node":"PAID Gemini","type":"ai_memory","index":0}]]},"Simple Memory5":{"ai_memory":[[{"node":"PAID NanoBanana","type":"ai_memory","index":0}]]},"SSH Command on Testing System":{"main":[[{"node":"Respond to Webhook","type":"main","index":0},{"node":"Respond to Chat2","type":"main","index":0}]]},"Linear Issues by Project":{"main":[[{"node":"Message a model1","type":"main","index":0}]]},"Message a model1":{"main":[[{"node":"Respond to Chat1","type":"main","index":0}]]},"Current Full Prompt":{"main":[[{"node":"Get row(s)","type":"main","index":0}]]},"Set Active Command and Separate Prompt":{"main":[[{"node":"Upsert row(s)","type":"main","index":0}]]},"Upsert row(s)":{"main":[[{"node":"Switch","type":"main","index":0}]]},"Get row(s)":{"main":[[{"node":"Set Active Command and Separate Prompt","type":"main","index":0}]]},"openwebui-chat":{"main":[[{"node":"Orchestrator","type":"main","index":0}]]},"OpenAI Chat Model":{"ai_languageModel":[[{"node":"Orchestrator","type":"ai_languageModel","index":0}]]},"Simple Memory6":{"ai_memory":[[{"node":"Orchestrator","type":"ai_memory","index":0}]]},"Respond to Webhook":{"main":[[]]},"Respond to Chat2":{"main":[[{"node":"Save SubAgent Output","type":"main","index":0}]]},"If":{"main":[[{"node":"Current Full Prompt","type":"main","index":0}],[{"node":"Respond to Chat3","type":"main","index":0}]]},"Get row(s) in Data table":{"ai_tool":[[{"node":"Orchestrator","type":"ai_tool","index":0}]]},"Respond to Chat3":{"main":[[{"node":"Save Message and Prompt","type":"main","index":0}]]},"PAID Anthropic":{"main":[[{"node":"Respond to Webhook","type":"main","index":0},{"node":"Respond to Chat2","type":"main","index":0}]]},"Orchestrator":{"main":[[{"node":"If","type":"main","index":0}]]},"OpenAI Chat Model1":{"ai_languageModel":[[{"node":"Project Agent","type":"ai_languageModel","index":0}]]},"Simple Memory7":{"ai_memory":[[{"node":"Project Agent","type":"ai_memory","index":0}]]}},"authors":"Bill Griffith","name":"WORKING BETA","description":"","workflowPublishHistory":[{"createdAt":"2025-12-25T03:51:02.434Z","id":180,"workflowId":"ud7XYHk6QWFvgDxf","versionId":"de071a94-bbce-4c4a-9b27-6626cc1fe03e","event":"activated","userId":"82ee42c3-23a4-46d2-8969-bfa414e739d3"}]}}